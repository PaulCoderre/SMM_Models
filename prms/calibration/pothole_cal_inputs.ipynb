{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a6460d-baa3-496e-8772-2536f45ac05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Set\n",
    "import networkx as nx\n",
    "from typing import List, Tuple\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107eaf0-63e3-4144-bfeb-3ed820445747",
   "metadata": {},
   "source": [
    "Par_Paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54f64fc-0fe5-49b1-8cd1-cd90c526e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nseg(file_path: str, target_id: int) -> List[int]:\n",
    "    '''Find upstream segments in a river network given\n",
    "    in the form of a text file between \"tosegment\" and \"#### \n",
    "    these represent the nseg index values to replace with parameters, the target ID is included in the list\n",
    "    because the gauge is assumed to be at the end of the segments\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path: str\n",
    "        Path to the text file containing river segment information\n",
    "    target_id: int\n",
    "        Target ID for which upstream segments are desired\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    nodes: list of int\n",
    "        IDs of upstream or ancestor segments\n",
    "    '''\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Convert lines to a NumPy array\n",
    "    data = np.array([line.strip() for line in lines])\n",
    "\n",
    "    # Find the index of 'tosegment'\n",
    "    start_index = np.where(data == 'tosegment')[0]\n",
    "\n",
    "    if len(start_index) == 0:\n",
    "        print(\"Target string 'tosegment' not found in the file.\")\n",
    "        return []\n",
    "\n",
    "    start_index = start_index[0]\n",
    "\n",
    "    # Find the index of the next '####'\n",
    "    end_index = np.where(data == '####')[0]\n",
    "\n",
    "    if len(end_index) == 0:\n",
    "        print(\"No '####' found after 'tosegment'.\")\n",
    "        return []\n",
    "\n",
    "    end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "    if len(end_index) == 0:\n",
    "        print(\"No '####' found after 'tosegment'.\")\n",
    "        return []\n",
    "\n",
    "    end_index = end_index[0]\n",
    "\n",
    "    start_index += 5\n",
    "    \n",
    "    result_array = data[start_index:end_index]\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({'upstream_segments': result_array}, index=np.arange(1, len(result_array) + 1))\n",
    "    \n",
    "    # Convert index to strings\n",
    "    df.index = df.index.astype(str)\n",
    "\n",
    "    # Creating a DiGraph out of `df` object\n",
    "    riv_graph = nx.from_pandas_edgelist(df.reset_index(), source='index', target='upstream_segments', create_using=nx.DiGraph)\n",
    "    \n",
    "    # Return nodes as a list of integers, including the target_id\n",
    "    nodes = nx.ancestors(riv_graph, str(target_id))\n",
    "    nodes_list = list(map(int, nodes)) + [target_id]\n",
    "\n",
    "    return nodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b7e94e0-b973-44a4-9b33-e0838d29e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(list1, list2):\n",
    "    '''Find unique values from two lists.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list1: list of int\n",
    "        First list of integers\n",
    "    list2: list of int\n",
    "        Second list of integers\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    unique_values: list of int\n",
    "        List of unique values from both lists\n",
    "    '''\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    \n",
    "    # Find unique values from both sets\n",
    "    unique_values = list(set1.symmetric_difference(set2))\n",
    "    \n",
    "    return unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0cbe6a7-812a-4009-afd1-bcb7d2f3416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_nseg(list1, list2):\n",
    "    '''Merge two lists and find unique values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list1: list of int\n",
    "        First list of integers\n",
    "    list2: list of int\n",
    "        Second list of integers\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    unique_values: list of int\n",
    "        List of unique values from both lists\n",
    "    '''\n",
    "    merged_list = list1 + list2\n",
    "    unique_values = list(set(merged_list))\n",
    "    \n",
    "    return unique_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29fef248-5159-41e3-b6be-a6d8330c4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nhru(file_path: str, nseg: list) -> List[int]:\n",
    "    ''' find the corresponding nhru index positions to the nseg\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path: str\n",
    "        Path to the text file containing river segment information\n",
    "        \n",
    "    nseg: list of index positions of upstream river segments\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    nhru: list of hru values corresponding to the segments\n",
    "    \n",
    "    '''\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Convert lines to a NumPy array\n",
    "    data = np.array([line.strip() for line in lines])\n",
    "\n",
    "    # Find the index of 'tosegment'\n",
    "    start_index = np.where(data == 'hru_segment')[0]\n",
    "\n",
    "    if len(start_index) == 0:\n",
    "        print(\"Target string 'tosegment' not found in the file.\")\n",
    "        return []\n",
    "\n",
    "    start_index = start_index[0]\n",
    "\n",
    "    # Find the index of the next '####'\n",
    "    end_index = np.where(data == '####')[0]\n",
    "\n",
    "    if len(end_index) == 0:\n",
    "        print(\"No '####' found after 'tosegment'.\")\n",
    "        return []\n",
    "\n",
    "    end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "    if len(end_index) == 0:\n",
    "        print(\"No '####' found after 'tosegment'.\")\n",
    "        return []\n",
    "\n",
    "    end_index = end_index[0]\n",
    "\n",
    "    start_index += 5\n",
    "    \n",
    "    result_array = data[start_index:end_index]\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({'corresponding hru': result_array}, index=np.arange(1, len(result_array) + 1))\n",
    "\n",
    "    # Find corresponding nhru values for each nseg\n",
    "    nhru_values = []\n",
    "    for seg in nseg:\n",
    "        # Find index positions where seg is present in the first column\n",
    "        indices = np.where(df['corresponding hru'] == str(seg))[0] + 1  # Adding 1 to convert to 1-based index\n",
    "        nhru_values.extend(indices)\n",
    "\n",
    "    return nhru_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1ab0e6-c879-471a-916a-ba5a2402b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nseg(array: np.ndarray, dataframe: pd.DataFrame, nhru_results: List[int], updated_strings: List[List[str]]) -> np.ndarray:\n",
    "    '''Filter the DataFrame based on the 'Count' column values of 908 or 909.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        NumPy array (to be updated).\n",
    "    dataframe: pd.DataFrame\n",
    "        DataFrame to be filtered.\n",
    "    nhru_results: List[int]\n",
    "        List of nhru values.\n",
    "    updated_strings: List[List[str]]\n",
    "        2D List to store updated strings (each row: [original_string, numerical_value, updated_string]).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    updated_array: np.ndarray\n",
    "        Updated NumPy array with index numbers rewritten as strings.\n",
    "    '''\n",
    "    # Filter the DataFrame based on 'Count' column values\n",
    "    filtered_dataframe = dataframe[dataframe['Count'].isin([448, 449])]\n",
    "    \n",
    "    # Iterate through strings in the index of the filtered DataFrame\n",
    "    for string_to_find in filtered_dataframe.index:\n",
    "        # Find the index of 'tosegment'\n",
    "        start_index = np.where(array == string_to_find)[0]\n",
    "\n",
    "        if len(start_index) == 0:\n",
    "            print(f\"Target string '{string_to_find}' not found in the array.\")\n",
    "            continue\n",
    "\n",
    "        start_index = start_index[0]\n",
    "\n",
    "        # Find the index of the next '####'\n",
    "        end_index = np.where(array == '####')[0]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[0]\n",
    "\n",
    "        # Skip the first 4 lines for nseg\n",
    "        start_index += 5\n",
    "\n",
    "        # Save the range between start and end index to a NumPy array\n",
    "        result_array = np.arange(start_index, end_index + 1)\n",
    "\n",
    "        # Iterate through the list of nhru_results and update the corresponding indices\n",
    "        for nhru_value in nhru_results:\n",
    "            # Map nhru_value to the corresponding index in result_array\n",
    "            index_to_update = nhru_value - 1\n",
    "\n",
    "            if index_to_update < 0 or index_to_update >= len(result_array):\n",
    "                print(f\"Index value '{nhru_value}' is out of range for '{string_to_find}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Save the numerical value being overwritten\n",
    "            original_value = array[result_array[index_to_update]]\n",
    "\n",
    "            # Update the array with the new string format\n",
    "            updated_value = f'___{string_to_find}{nhru_value}_A'\n",
    "            array[result_array[index_to_update]] = updated_value\n",
    "\n",
    "            # Append the updated string to the 2D list\n",
    "            updated_strings.append([string_to_find, original_value, updated_value])\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6d114f-df6f-4d7a-98c2-152e9aef9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nhru(array: np.ndarray, dataframe: pd.DataFrame, nhru_results: List[int], updated_strings: List[List[str]]) -> np.ndarray:\n",
    "    '''Filter the DataFrame based on the 'Count' column values of 908 or 909.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        NumPy array (to be updated).\n",
    "    dataframe: pd.DataFrame\n",
    "        DataFrame to be filtered.\n",
    "    nhru_results: List[int]\n",
    "        List of nhru values.\n",
    "    updated_strings: List[List[str]]\n",
    "        2D List to store updated strings (each row: [original_string, numerical_value, updated_string]).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    updated_array: np.ndarray\n",
    "        Updated NumPy array with index numbers rewritten as strings.\n",
    "    '''\n",
    "    # Filter the DataFrame based on 'Count' column values\n",
    "    filtered_dataframe = dataframe[dataframe['Count'].isin([908, 909])]\n",
    "    \n",
    "    # Iterate through strings in the index of the filtered DataFrame\n",
    "    for string_to_find in filtered_dataframe.index:\n",
    "        # Find the index of 'tosegment'\n",
    "        start_index = np.where(array == string_to_find)[0]\n",
    "\n",
    "        if len(start_index) == 0:\n",
    "            print(f\"Target string '{string_to_find}' not found in the array.\")\n",
    "            continue\n",
    "\n",
    "        start_index = start_index[0]\n",
    "\n",
    "        # Find the index of the next '####'\n",
    "        end_index = np.where(array == '####')[0]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[0]\n",
    "\n",
    "        # Skip the first 4 lines for nhru\n",
    "        start_index += 5\n",
    "\n",
    "        # Save the range between start and end index to a NumPy array\n",
    "        result_array = np.arange(start_index, end_index + 1)\n",
    "\n",
    "        # Iterate through the list of nhru_results and update the corresponding indices\n",
    "        for nhru_value in nhru_results:\n",
    "            # Map nhru_value to the corresponding index in result_array\n",
    "            index_to_update = nhru_value - 1\n",
    "\n",
    "            if index_to_update < 0 or index_to_update >= len(result_array):\n",
    "                print(f\"Index value '{nhru_value}' is out of range for '{string_to_find}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Save the numerical value being overwritten\n",
    "            original_value = array[result_array[index_to_update]]\n",
    "\n",
    "            # Update the array with the new string format\n",
    "            updated_value = f'___{string_to_find}{nhru_value}_A'\n",
    "            array[result_array[index_to_update]] = updated_value\n",
    "\n",
    "            # Append the updated string to the 2D list\n",
    "            updated_strings.append([string_to_find, original_value, updated_value])\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8671ad-cf58-4896-ad03-929ee4b2f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nmonths(array: np.ndarray, dataframe: pd.DataFrame, nhru_results: List[int], updated_strings: List[List[str]]) -> np.ndarray:\n",
    "    '''Filter the DataFrame based on the 'Count' column values of 908 or 909.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        NumPy array (to be updated).\n",
    "    dataframe: pd.DataFrame\n",
    "        DataFrame to be filtered.\n",
    "    nhru_results: List[int]\n",
    "        List of nhru values.\n",
    "    updated_strings: List[List[str]]\n",
    "        2D List to store updated strings (each row: [original_string, numerical_value, updated_string]).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    updated_array: np.ndarray\n",
    "        Updated NumPy array with index numbers rewritten as strings.\n",
    "    '''\n",
    "    # Filter the DataFrame based on 'Count' column values\n",
    "    filtered_dataframe = dataframe[dataframe['Count'].isin([10908, 10909])]\n",
    "    \n",
    "    # Iterate through strings in the index of the filtered DataFrame\n",
    "    for string_to_find in filtered_dataframe.index:\n",
    "        # Find the index of 'tosegment'\n",
    "        start_index = np.where(array == string_to_find)[0]\n",
    "\n",
    "        if len(start_index) == 0:\n",
    "            print(f\"Target string '{string_to_find}' not found in the array.\")\n",
    "            continue\n",
    "\n",
    "        start_index = start_index[0]\n",
    "\n",
    "        # Find the index of the next '####'\n",
    "        end_index = np.where(array == '####')[0]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[0]\n",
    "\n",
    "        # Skip the first 5 lines for nmonths\n",
    "        start_index += 6\n",
    "\n",
    "        # Save the range between start and end index to a NumPy array\n",
    "        result_array = np.arange(start_index, end_index + 1)\n",
    "\n",
    "        # Iterate through the list of nhru_results and update the corresponding indices\n",
    "        for nhru_value in nhru_results:\n",
    "            # Map nhru_value to the corresponding index in result_array\n",
    "            index_to_update = (nhru_value - 1) * 12\n",
    "\n",
    "            if index_to_update < 0 or index_to_update + 11 >= len(array):\n",
    "                print(f\"Index value '{nhru_value}' is out of range for '{string_to_find}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Save the numerical values being overwritten\n",
    "            original_values = array[result_array[index_to_update:index_to_update + 12]]\n",
    "\n",
    "            for i in range(12):\n",
    "                # Use letters A-L at the end instead of double digits\n",
    "                updated_value = f'___{string_to_find}{nhru_value}_{string.ascii_uppercase[i]}'\n",
    "                array[result_array[index_to_update + i]] = updated_value\n",
    "\n",
    "                # Append the updated string to the 2D list\n",
    "                updated_strings.append([string_to_find, original_values[i], updated_value])\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ebe6d8-f57b-4c77-93ac-800ebffc130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_alt_input(array: np.ndarray, dataframe: pd.DataFrame, nhru_results: List[int], updated_strings: List[List[str]]) -> pd.DataFrame:\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        NumPy array (to be updated).\n",
    "    dataframe: pd.DataFrame\n",
    "        DataFrame to be filtered.\n",
    "    nhru_results: List[int]\n",
    "        List of nhru values.\n",
    "    updated_strings: List[List[str]]\n",
    "        2D List to store updated strings (each row: [original_string, numerical_value, updated_string]).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_dataframe: pd.DataFrame\n",
    "        New DataFrame with 'nhru' as the index and columns named after the row index in the filtered DataFrame, filled with 1.\n",
    "    '''\n",
    "    # Filter the DataFrame based on 'Count' column values\n",
    "    filtered_dataframe = dataframe[dataframe['Count'].isin([10908, 10909])]\n",
    "    \n",
    "    # Create a new DataFrame with 'nhru' as the index and specified columns\n",
    "    new_dataframe = pd.DataFrame(index=nhru_results, columns=filtered_dataframe.index.astype(str))\n",
    "    \n",
    "    # Fill all values in the new DataFrame with 1\n",
    "    new_param= new_dataframe.fillna(1)\n",
    "    \n",
    "        # Extract column names as a list\n",
    "    column_names = new_dataframe.columns.tolist()\n",
    "    \n",
    "    # Iterate through each column and populate with strings\n",
    "    for column_name in new_dataframe.columns:\n",
    "        for row_index in new_dataframe.index:\n",
    "            value = f'___adjust_{column_name}_{row_index}_A'\n",
    "            new_dataframe.at[row_index, column_name] = value\n",
    "            updated_strings.append([column_name, new_dataframe.at[row_index, column_name], value])\n",
    "    \n",
    "    return new_param, new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d09adab-d558-4313-8a92-cd3c03bf9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obsin_segment(array: np.ndarray, seg: int, obs: int) -> np.ndarray:\n",
    "    '''Replace the inflow to a segment with observed flow.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        NumPy array (to be updated).\n",
    "    seg: int\n",
    "        Segment to replace.\n",
    "    obs: int\n",
    "        Index of observed flow.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    updated_array: np.ndarray\n",
    "        Updated NumPy array with index numbers replaced by observed flow.\n",
    "    '''\n",
    "\n",
    "    # Find the index of 'obsin_segment'\n",
    "    start_index = np.where(array == 'obsin_segment')[0]\n",
    "\n",
    "    if len(start_index) == 0:\n",
    "        print(\"Target string 'obsin_segment' not found in the array.\")\n",
    "        return array\n",
    "\n",
    "    start_index = start_index[0]\n",
    "\n",
    "    # Find the index of the next '####'\n",
    "    end_index = np.where(array == '####')[0]\n",
    "\n",
    "    if len(end_index) == 0:\n",
    "        print(\"No '####' found after 'obsin_segment'.\")\n",
    "        return array\n",
    "\n",
    "    end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "    if len(end_index) == 0:\n",
    "        print(\"No '####' found after 'obsin_segment'.\")\n",
    "        return array\n",
    "\n",
    "    end_index = end_index[0]\n",
    "\n",
    "    # Skip the first 4 lines for nseg\n",
    "    start_index += 5\n",
    "\n",
    "    # Save the range between start and end index to a NumPy array\n",
    "    result_array = np.arange(start_index, end_index + 1)\n",
    "\n",
    "    # Map seg to the corresponding index in result_array\n",
    "    index_to_update = seg - 1\n",
    "\n",
    "    if index_to_update < 0 or index_to_update >= len(result_array):\n",
    "        print(f\"Index value '{seg}' is out of range for 'obsin_segment'. Skipping.\")\n",
    "        return array\n",
    "\n",
    "    # Update the array with the observed flow value\n",
    "    array[result_array[index_to_update]] = obs\n",
    "\n",
    "    return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14983c26-c2bc-48ff-891c-52b10a0eb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ostin_table(ostin_table: pd.DataFrame, updated_strings: np.ndarray) -> pd.DataFrame:\n",
    "    '''\n",
    "    Generate a new DataFrame based on specified conditions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ostin_table : pd.DataFrame\n",
    "        DataFrame containing 'ostin_table' data.\n",
    "\n",
    "    updated_strings : np.ndarray\n",
    "        2D array containing numerical values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_dataframe : pd.DataFrame\n",
    "        A new DataFrame generated based on the specified conditions.\n",
    "    '''\n",
    "    # Create a DataFrame from the updated_strings data\n",
    "    updated_strings_df = pd.DataFrame(updated_strings, columns=['Parameter', 'Original_Value', 'Updated_String'])\n",
    "\n",
    "    # Set the 'Parameter' column as the index for quick lookups\n",
    "    ostin_table.index.name = 'Parameter'\n",
    "    updated_strings_df.set_index('Parameter', inplace=True)\n",
    "\n",
    "    # Change the original values of 0 to 0.01\n",
    "    updated_strings_df['Original_Value'] = pd.to_numeric(updated_strings_df['Original_Value'], errors='coerce')\n",
    "    updated_strings_df['Original_Value'].replace(0, 0.01, inplace=True)\n",
    "\n",
    "    for parameter_name in updated_strings_df.index.unique():\n",
    "        # Find corresponding values in ostin_table\n",
    "        if parameter_name in ostin_table.index:\n",
    "            low_bound = ostin_table.loc[parameter_name, 'low_bound']\n",
    "            upper_bound = ostin_table.loc[parameter_name, 'upper_bound']\n",
    "\n",
    "            # Check if the low_bound is -9999\n",
    "            if low_bound == -9999:\n",
    "                original_values = updated_strings_df.loc[parameter_name, 'Original_Value']\n",
    "                updated_strings_df.loc[parameter_name, 'Low_Bound'] = 0.8 * original_values\n",
    "            else:\n",
    "                updated_strings_df.loc[parameter_name, 'Low_Bound'] = low_bound\n",
    "\n",
    "            # Check if the upper_bound is -9999\n",
    "            if upper_bound == -9999:\n",
    "                original_values = updated_strings_df.loc[parameter_name, 'Original_Value']\n",
    "                updated_strings_df.loc[parameter_name, 'Upper_Bound'] = 1.2 * original_values\n",
    "            else:\n",
    "                updated_strings_df.loc[parameter_name, 'Upper_Bound'] = upper_bound\n",
    "\n",
    "    # Set the \"Updated_String\" column as the index\n",
    "    updated_strings_df = updated_strings_df.set_index('Updated_String')\n",
    "\n",
    "    # Add three new columns filled with 'none'\n",
    "    updated_strings_df['1'] = 'none'\n",
    "    updated_strings_df['2'] = 'none'\n",
    "    updated_strings_df['3'] = 'none'\n",
    "    \n",
    "    # optionally use keyword extract\n",
    "    # updated_strings_df['Original_Value']= 'extract'\n",
    "    \n",
    "        # Replace NaN values in 'Original_Value' with 1\n",
    "    updated_strings_df['Original_Value'].fillna(1, inplace=True)\n",
    "    \n",
    "    return updated_strings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29887873-3566-486b-96da-6e33118bc2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nseg_results(array: np.ndarray, dataframe: pd.DataFrame, nhru_results: List[int], final_par: np.ndarray) -> np.ndarray:\n",
    "    '''Filter the DataFrame based on the 'Count' column values of 908 or 909.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        NumPy array (to be updated).\n",
    "    dataframe: pd.DataFrame\n",
    "        DataFrame to be filtered.\n",
    "    nhru_results: List[int]\n",
    "        List of nhru values.\n",
    "    updated_strings: List[List[str]]\n",
    "        2D List to store updated strings (each row: [original_string, numerical_value, updated_string]).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    updated_array: np.ndarray\n",
    "        Updated NumPy array with index numbers rewritten as strings.\n",
    "    '''\n",
    "    # Filter the DataFrame based on 'Count' column values\n",
    "    filtered_dataframe = dataframe[dataframe['Count'].isin([448, 449])]\n",
    "    \n",
    "    # Iterate through strings in the index of the filtered DataFrame\n",
    "    for string_to_find in filtered_dataframe.index:\n",
    "        # Find the index of 'tosegment'\n",
    "        start_index = np.where(array == string_to_find)[0]\n",
    "\n",
    "        if len(start_index) == 0:\n",
    "            print(f\"Target string '{string_to_find}' not found in the array.\")\n",
    "            continue\n",
    "\n",
    "        start_index = start_index[0]\n",
    "\n",
    "        # Find the index of the next '####'\n",
    "        end_index = np.where(array == '####')[0]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[0]\n",
    "\n",
    "        # Skip the first 4 lines for nseg\n",
    "        start_index += 5\n",
    "\n",
    "        # Save the range between start and end index to a NumPy array\n",
    "        result_array = np.arange(start_index, end_index + 1)\n",
    "\n",
    "        # Iterate through the list of nhru_results and update the corresponding indices\n",
    "        for nhru_value in nhru_results:\n",
    "            # Map nhru_value to the corresponding index in result_array\n",
    "            index_to_update = nhru_value - 1\n",
    "\n",
    "            if index_to_update < 0 or index_to_update >= len(result_array):\n",
    "                print(f\"Index value '{nhru_value}' is out of range for '{string_to_find}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Copy the value from the original array to the final_par array\n",
    "            final_par[result_array[index_to_update]] = array[result_array[index_to_update]]\n",
    "\n",
    "    return final_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d012dc0b-0372-49ae-87b2-eb51f99e4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nhru_results(array: np.ndarray, dataframe: pd.DataFrame, nhru_results: List[int], final_par: np.ndarray) -> np.ndarray:\n",
    "    '''Filter the DataFrame based on the 'Count' column values of 908 or 909.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        NumPy array (to be updated).\n",
    "    dataframe: pd.DataFrame\n",
    "        DataFrame to be filtered.\n",
    "    nhru_results: List[int]\n",
    "        List of nhru values.\n",
    "    updated_strings: List[List[str]]\n",
    "        2D List to store updated strings (each row: [original_string, numerical_value, updated_string]).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    updated_array: np.ndarray\n",
    "        Updated NumPy array with index numbers rewritten as strings.\n",
    "    '''\n",
    "    \n",
    "    # Filter the DataFrame based on 'Count' column values\n",
    "    filtered_dataframe = dataframe[dataframe['Count'].isin([908, 909])]\n",
    "    \n",
    "    # Iterate through strings in the index of the filtered DataFrame\n",
    "    for string_to_find in filtered_dataframe.index:\n",
    "        # Find the index of 'tosegment'\n",
    "        start_index = np.where(final_par == string_to_find)[0]\n",
    "\n",
    "        if len(start_index) == 0:\n",
    "            print(f\"Target string '{string_to_find}' not found in the array.\")\n",
    "            continue\n",
    "\n",
    "        start_index = start_index[0]\n",
    "\n",
    "        # Find the index of the next '####'\n",
    "        end_index = np.where(final_par == '####')[0]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[0]\n",
    "\n",
    "        # Skip the first 4 lines for nhru\n",
    "        start_index += 5\n",
    "\n",
    "        # Save the range between start and end index to a NumPy array\n",
    "        result_array = np.arange(start_index, end_index + 1)\n",
    "\n",
    "        # Iterate through the list of nhru_results and update the corresponding indices\n",
    "        for nhru_value in nhru_results:\n",
    "            # Map nhru_value to the corresponding index in result_array\n",
    "            index_to_update = nhru_value - 1\n",
    "\n",
    "            if index_to_update < 0 or index_to_update >= len(result_array):\n",
    "                print(f\"Index value '{nhru_value}' is out of range for '{string_to_find}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Copy the value from the original array to the final_par array\n",
    "            final_par[result_array[index_to_update]] = array[result_array[index_to_update]]\n",
    "\n",
    "    return final_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cea1a401-b351-4072-b579-aca0c0174efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nmonths_results(array: np.ndarray, dataframe: pd.DataFrame, nhru_results: List[int], final_par: np.ndarray) -> np.ndarray:\n",
    "    '''Filter the DataFrame based on the 'Count' column values of 908 or 909.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        NumPy array (to be updated).\n",
    "    dataframe: pd.DataFrame\n",
    "        DataFrame to be filtered.\n",
    "    nhru_results: List[int]\n",
    "        List of nhru values.\n",
    "    updated_strings: List[List[str]]\n",
    "        2D List to store updated strings (each row: [original_string, numerical_value, updated_string]).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    updated_array: np.ndarray\n",
    "        Updated NumPy array with index numbers rewritten as strings.\n",
    "    '''\n",
    "    # Filter the DataFrame based on 'Count' column values\n",
    "    filtered_dataframe = dataframe[dataframe['Count'].isin([10908, 10909])]\n",
    "    \n",
    "    # Iterate through strings in the index of the filtered DataFrame\n",
    "    for string_to_find in filtered_dataframe.index:\n",
    "        # Find the index of 'tosegment'\n",
    "        start_index = np.where(array == string_to_find)[0]\n",
    "\n",
    "        if len(start_index) == 0:\n",
    "            print(f\"Target string '{string_to_find}' not found in the array.\")\n",
    "            continue\n",
    "\n",
    "        start_index = start_index[0]\n",
    "\n",
    "        # Find the index of the next '####'\n",
    "        end_index = np.where(array == '####')[0]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[0]\n",
    "\n",
    "        # Skip the first 5 lines for nmonths\n",
    "        start_index += 6\n",
    "\n",
    "        # Save the range between start and end index to a NumPy array\n",
    "        result_array = np.arange(start_index, end_index + 1)\n",
    "\n",
    "        # Iterate through the list of nhru_results and update the corresponding indices\n",
    "        for nhru_value in nhru_results:\n",
    "            # Map nhru_value to the corresponding index in result_array\n",
    "            index_to_update = (nhru_value - 1) * 12\n",
    "\n",
    "            if index_to_update < 0 or index_to_update + 11 >= len(array):\n",
    "                print(f\"Index value '{nhru_value}' is out of range for '{string_to_find}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            for i in range(12):\n",
    "            # Copy the value from array to final_par\n",
    "                final_par[result_array[index_to_update + i]] = array[result_array[index_to_update + i]]\n",
    "\n",
    "\n",
    "    return final_par"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc51877a-2850-48a7-ba97-b554f8a79afb",
   "metadata": {},
   "source": [
    "### Calibration inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bb5f084-dae4-4c9b-a0ef-dae15beab847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "file_path = '/home/paulc600/scratch/prms_final/par_files/template_myparam.param' # ensure its the updated par file\n",
    "output_file_path = './data/paired_myparam.param'\n",
    "ostin_filepath= './ostIn.txt'\n",
    "target_ID= 195\n",
    "upstream_ID_1= 24 # to remove hrus upstream of a previous gauge\n",
    "upstream_ID_2= 429 # to remove hrus upstream of a previous gauge\n",
    "updated_strings = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82bd7b-5df1-469d-bbe3-fed258e658d0",
   "metadata": {},
   "source": [
    "### Final result inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53e0099e-3fb2-43c1-878c-95ad9081fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_result= './mod_0/data/myparam.param' # ensure you run the script first to check KGE and update adj factor\n",
    "final_par= '../par_files/template_myparam.param'\n",
    "final_par_output= '/home/paulc600/scratch/prms_final/par_files/myparam.param'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f27a00b-dbe6-4863-9721-2f0716be13f1",
   "metadata": {},
   "source": [
    "### Paired Parameter File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a9fba5e-02d4-4ee0-8a1e-01fb4106d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the calibration parameter file into a DataFrame\n",
    "cal_param = pd.read_csv('../PRMS_pothole_par.txt',encoding='utf-16', sep= '\\t', header= 0, index_col=0)\n",
    "#cal_param.rename(columns={cal_param.columns[0]: 'low_bound'}, inplace=True)\n",
    "#cal_param.rename(columns={cal_param.columns[1]: 'upper_bound'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31de3d4a-cf42-40f6-84c8-e2912816ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Par File into a numpy array to convert to Paired    \n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "par_paired = np.array([line.strip() for line in lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0952a-f50c-4e31-9691-f699f3b9386e",
   "metadata": {},
   "source": [
    "Define river segment list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d45c46a4-34c9-4fa4-aa0a-422f5fc80528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find upstream nseg index values which can be used to write nseg parameters\n",
    "nseg= find_nseg(file_path, target_ID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a782b9f-5568-4f48-8025-a7b0b6c4df40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nseg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ec2b62-074b-4296-8471-ad99bc194df7",
   "metadata": {},
   "source": [
    "### Add previous segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5945c6-971d-4a0e-8c6a-31ee8b7f1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find previous or upstream gauge\n",
    "# previous_nseg1= find_nseg(file_path, upstream_ID_1)\n",
    "# previous_nseg2= find_nseg(file_path, upstream_ID_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6ff57de-0d6e-4da2-a502-27fe80f29195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove previous gauge\n",
    "# nseg= remove_duplicates(nseg, previous_nseg1)\n",
    "# nseg= remove_duplicates(nseg, previous_nseg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b94b4603-8089-48c9-be28-e681eb7c9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine gauge nseg lists\n",
    "#nseg= combine_nseg(nseg,nseg)\n",
    "# nseg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65517527-a27c-4f17-8755-276b15c2c922",
   "metadata": {},
   "source": [
    "### Find nhru and write paired parameter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88959f2b-512d-4de4-b71d-e173fbe8f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhru= find_nhru(file_path, nseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c073f614-dd95-4733-8411-9fc0a28b2ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nhru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55bae9c2-e1e3-4862-86ae-aebd3b258f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_paired= write_nseg(par_paired, cal_param, nseg, updated_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fdb244a-a18f-4374-a6c6-c970591c80ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "par_paired= write_nhru(par_paired, cal_param, nhru, updated_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa817709-befc-41f0-9128-7300e556b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly, monthly_paired= write_alt_input(par_paired, cal_param, nhru, updated_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab6400-f26b-41ba-a2d3-e908eae26fb6",
   "metadata": {},
   "source": [
    "### Obsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34aad34f-2775-4807-9b7d-c79f04c0f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace inflow to segment with observed flow\n",
    "# par_paired=obsin_segment(par_paired, 21, 0)\n",
    "# par_paired=obsin_segment(par_paired, 353, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e75ae-f860-47d9-853e-e55f43f0d9ed",
   "metadata": {},
   "source": [
    "### Write ostin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fcb7f36-5c32-4c91-855c-fb572fd9d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ostin= write_ostin_table(cal_param, updated_strings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5795060-25c7-4a66-bc15-20f85628e242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Value</th>\n",
       "      <th>Low_Bound</th>\n",
       "      <th>Upper_Bound</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Updated_String</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>___carea_max521_A</th>\n",
       "      <td>0.161881</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>___carea_max522_A</th>\n",
       "      <td>0.188090</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>___carea_max494_A</th>\n",
       "      <td>0.184166</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>___carea_max497_A</th>\n",
       "      <td>0.175683</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>___carea_max495_A</th>\n",
       "      <td>0.229220</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>___adjust_tmin_cbh_adj_527_A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>−3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>___adjust_tmin_cbh_adj_549_A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>−3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>___adjust_tmin_cbh_adj_568_A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>−3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>___adjust_tmin_cbh_adj_563_A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>−3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>___adjust_tmin_cbh_adj_574_A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>−3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Original_Value Low_Bound  Upper_Bound     1  \\\n",
       "Updated_String                                                              \n",
       "___carea_max521_A                   0.161881       0.1          0.9  none   \n",
       "___carea_max522_A                   0.188090       0.1          0.9  none   \n",
       "___carea_max494_A                   0.184166       0.1          0.9  none   \n",
       "___carea_max497_A                   0.175683       0.1          0.9  none   \n",
       "___carea_max495_A                   0.229220       0.1          0.9  none   \n",
       "...                                      ...       ...          ...   ...   \n",
       "___adjust_tmin_cbh_adj_527_A        1.000000        −3          3.0  none   \n",
       "___adjust_tmin_cbh_adj_549_A        1.000000        −3          3.0  none   \n",
       "___adjust_tmin_cbh_adj_568_A        1.000000        −3          3.0  none   \n",
       "___adjust_tmin_cbh_adj_563_A        1.000000        −3          3.0  none   \n",
       "___adjust_tmin_cbh_adj_574_A        1.000000        −3          3.0  none   \n",
       "\n",
       "                                 2     3  \n",
       "Updated_String                            \n",
       "___carea_max521_A             none  none  \n",
       "___carea_max522_A             none  none  \n",
       "___carea_max494_A             none  none  \n",
       "___carea_max497_A             none  none  \n",
       "___carea_max495_A             none  none  \n",
       "...                            ...   ...  \n",
       "___adjust_tmin_cbh_adj_527_A  none  none  \n",
       "___adjust_tmin_cbh_adj_549_A  none  none  \n",
       "___adjust_tmin_cbh_adj_568_A  none  none  \n",
       "___adjust_tmin_cbh_adj_563_A  none  none  \n",
       "___adjust_tmin_cbh_adj_574_A  none  none  \n",
       "\n",
       "[592 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ostin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "704dfb3d-8d89-420f-9522-2a5421853728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom header and footer strings\n",
    "top_half = \"\"\"#Basic Configuration for Ostrich Program\n",
    "\n",
    "#Essential variables\n",
    "ProgramType ParallelDDS\n",
    "ModelExecutable ./run-adj.sh\n",
    "ModelSubdir mod_\n",
    "ObjectiveFunction GCOP\n",
    "OstrichWarmStart no\n",
    "\n",
    "#Template File Configuration\n",
    "BeginFilePairs\n",
    "data/paired_myparam.param ; data/myparam.param\n",
    "data/paired_monthly.txt ; data/monthly.txt\n",
    "EndFilePairs\n",
    "\n",
    "BeginExtraFiles\n",
    "EndExtraFiles\n",
    "\n",
    "BeginExtraDirs\n",
    "data\n",
    "EndExtraDirs\n",
    "\n",
    "\n",
    "BeginParams\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e20db137-2ab2-48a1-ae30-b97d48f23c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_half= \"\"\"EndParams\n",
    "\n",
    "#Output variables to analyze\n",
    "BeginResponseVars\n",
    "#name   filename            keyword         line    col     token\n",
    "KGE ./data/average_kge.txt ; OST_NULL 0 1 ' '\n",
    "EndResponseVars\n",
    "\n",
    "BeginGCOP\n",
    "CostFunction KGE\n",
    "PenaltyFunction APM\n",
    "EndGCOP\n",
    "\n",
    "#DDS algorithm setup\n",
    "BeginParallelDDSAlg\n",
    "PerturbationValue 0.2\n",
    "MaxIterations 50000\n",
    "UseInitialParamValues\n",
    "EndParallelDDSAlg\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25dde548-d03e-49b2-b218-49cd28e35aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a3bb7-3c77-4922-8bfa-0d840864efbd",
   "metadata": {},
   "source": [
    "### Calibration Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2d1a725-dfbd-4353-977e-13d3e45cefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrames to text files\n",
    "monthly.to_csv('./data/monthly.txt', sep=' ', index=True)\n",
    "monthly_paired.to_csv('./data/paired_monthly.txt', sep=' ', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7e53243-0ff3-4b75-a3a7-b6cdb04daf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parpaired to the specified file path\n",
    "np.savetxt(output_file_path, par_paired, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e48c40f-3508-4afe-a064-0e24e5c5e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to a text file with header and footer strings\n",
    "with open(ostin_filepath, 'w') as file:\n",
    "    file.write(top_half + '\\n')\n",
    "    ostin.to_csv(file, header=False, sep=' ')  # You can change the separator if needed\n",
    "    file.write(bottom_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984496a-806b-4fd2-b0a9-353f21483d97",
   "metadata": {},
   "source": [
    "### Update Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05776dea-7f40-46e3-8ee2-e3cddd2c9402",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './mod_0/data/myparam.param'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24132/2651607736.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read filepaths as filepath array as a NumPy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './mod_0/data/myparam.param'"
     ]
    }
   ],
   "source": [
    "    # Read filepaths as filepath array as a NumPy array\n",
    "    with open(cal_result, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    cal_result = np.array([line.strip() for line in lines])\n",
    "    \n",
    "        # Read filepaths as filepath array as a NumPy array\n",
    "    with open(final_par, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    final_par = np.array([line.strip() for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1530a-d97e-47b8-9093-c9e017a8ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy nseg cal results\n",
    "par= update_nseg_results(cal_result, filter_variables_coef_variation, nseg, final_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb21405-95da-4c7b-8dae-8a8c5d9ffaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "par= update_nhru_results(cal_result, filter_variables_coef_variation, nhru, final_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a860a3-cf25-485c-a0ca-c7f73ccbfb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "par= update_nmonths_results(cal_result, filter_variables_coef_variation, nhru, final_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49b607-d363-41d2-827e-00d09cb33965",
   "metadata": {},
   "source": [
    "np.savetxt(final_par_output, par, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea6f66-3092-4f83-82e1-4f1fe0e8aca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easymore-env",
   "language": "python",
   "name": "easymore-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
