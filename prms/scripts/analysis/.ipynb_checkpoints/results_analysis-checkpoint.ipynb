{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe3f683-4f41-4ce4-a3eb-9f2962c4440f",
   "metadata": {},
   "source": [
    "Note: make top line #!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370a9097-0137-4ef9-8a79-37ae07fffe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b9a899-e831-4463-83b0-9fbad3ae79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_adj(array: np.ndarray, dataframe: pd.DataFrame):\n",
    "    # Iterate through columns in the DataFrame\n",
    "    for column_name in dataframe.columns:\n",
    "        # Find the column name in the array\n",
    "        start_index = np.where(array == column_name)[0]\n",
    "\n",
    "        if len(start_index) == 0:\n",
    "            print(f\"Target string '{column_name}' not found in the array.\")\n",
    "            continue\n",
    "\n",
    "        start_index = start_index[0]\n",
    "\n",
    "        # Find the index of the next '####'\n",
    "        end_index = np.where(array == '####')[0]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[0]\n",
    "\n",
    "        # Skip the first 5 lines for nmonths\n",
    "        start_index += 6\n",
    "\n",
    "        # Save the range between start and end index to a NumPy array\n",
    "        result_array = np.arange(start_index, end_index + 1)\n",
    "\n",
    "        # Iterate through rows in the DataFrame\n",
    "        for row_index in dataframe.index:\n",
    "            # Map row_index to the corresponding index in result_array\n",
    "            index_to_update = (row_index - 1) * 12\n",
    "\n",
    "            if index_to_update < 0 or index_to_update + 11 >= len(array):\n",
    "                print(f\"Index value '{row_index}' is out of range for '{column_name}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Convert the array values to numeric before performing multiplication\n",
    "            array_values_numeric = pd.to_numeric(array[result_array[index_to_update:index_to_update + 12]])\n",
    "\n",
    "            # Perform updates by multiplying the array value by the corresponding one in the DataFrame\n",
    "            for i in range(12):\n",
    "                array[result_array[index_to_update + i]] = array_values_numeric[i] * dataframe.at[row_index, column_name]\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec8bd85-f21c-451b-aa34-deace0db9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_values(simulated, observed):\n",
    "    valid_indices = np.where((observed != -9999) & (simulated != -9999))\n",
    "    return simulated[valid_indices], observed[valid_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc825dd9-79bb-4bb7-94d3-998dac5c3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(\n",
    "    array1: np.ndarray, \n",
    "    array2: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Removes rows from two arrays where either array has NaN values.\n",
    "    Retains the first row if it doesn't have any NaN values.\n",
    "    \n",
    "    Arguments:\n",
    "    array1: np.ndarray:\n",
    "        First input array\n",
    "    array2: np.ndarray\n",
    "        Second input array\n",
    "    \n",
    "    Returns:\n",
    "    cleaned_array1: : np.ndarray\n",
    "        Cleaned array1 without NaN rows\n",
    "    cleaned_array2: np.ndarray\n",
    "        Cleaned array2 without NaN rows\n",
    "    \"\"\"\n",
    "    # checks for and removes any rows where either array has a value of NaN at a corresponding row \n",
    "    # including the first one\n",
    "    \n",
    "    mask = np.logical_and(~np.isnan(array1), ~np.isnan(array2))\n",
    "    if not np.isnan(array1[0]) and not np.isnan(array2[0]):\n",
    "        mask[0] = True\n",
    "    cleaned_array1 = array1[mask]\n",
    "    cleaned_array2 = array2[mask]\n",
    "    return cleaned_array1, cleaned_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74232359-b57b-41ff-a199-b8ed30fe03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kge(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes KGE (Kling-Gupta Efficiency) between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: KGE value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_coefficient = np.corrcoef(observed_array, simulated_array)[0, 1]\n",
    "    \n",
    "    # Calculate standard deviation ratio\n",
    "    std_observed = np.std(observed_array)\n",
    "    std_simulated = np.std(simulated_array)\n",
    "    std_ratio = std_simulated / std_observed\n",
    "    \n",
    "    # Calculate bias ratio\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    bias_ratio = mean_simulated / mean_observed\n",
    "    \n",
    "    # Calculate KGE\n",
    "    kge = 1 - np.sqrt((correlation_coefficient - 1)**2 + (std_ratio - 1)**2 + (bias_ratio - 1)**2)\n",
    "    return kge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c22918-f3ac-4b99-ba9e-ce8feb9250c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes bias between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: Bias value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate mean bias\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    \n",
    "    # Calculate bias\n",
    "    bias = mean_simulated - mean_observed\n",
    "       \n",
    "    # Calculate percent bias\n",
    "    percent_bias = (bias / mean_observed) * 100\n",
    "    \n",
    "    return percent_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e5afe9-4b80-4200-ad7c-e1f94dadf5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where your executable is located\n",
    "executable_directory = '../../model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe7d79c-f146-42b3-9bc1-95476b872ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the current working directory to the specified directory\n",
    "os.chdir(executable_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad59377-0ca9-45a3-8a4d-d6310396f433",
   "metadata": {},
   "source": [
    "# run prms\n",
    "subprocess.run(['./prms', '-C./control.default.bandit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b90ac-b60d-4129-8d92-30ff1de13a1c",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "557682c4-6132-41d6-b1b1-5e5a3e4b856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store total KGE values for each file\n",
    "calibrate_kge  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dadd457-87fa-4aff-87ef-c3412c58aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_kge= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "206b969d-4d3f-467d-b994-9ad2b5d266e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate_bias= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86004c29-abdc-4617-82e8-8b8b3fad4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_bias= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fff358a-f529-4a8a-b0b2-ee9f1125ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e37571b6-5cfc-47df-b50d-19b371bef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = [('1981-01-01', '1984-12-31'),\n",
    "               ('1990-01-01', '1998-12-31'),\n",
    "               ('2004-01-01', '2007-12-31'),\n",
    "               ('2013-01-01', '2015-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b5cc19-a2bc-4a2e-b576-3b906122287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = [('1985-01-01', '1989-12-31'),\n",
    "               ('1999-01-01', '2003-12-31'),\n",
    "               ('2008-01-01', '2012-12-31')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc178a5-32f2-4ee0-9482-4f6cbb525292",
   "metadata": {},
   "source": [
    "### Read statvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2b3ae68-3d6f-4380-90e6-d1c4fc8553b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../model/statvar.out'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read space-separated file into DataFrame, skipping 28 rows\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m simulated \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../model/statvar.out\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m29\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../model/statvar.out'"
     ]
    }
   ],
   "source": [
    "    # Read space-separated file into DataFrame, skipping 28 rows\n",
    "simulated = pd.read_csv('./statvar.out', sep=' ', skiprows=29, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85845192-8af6-4c67-a916-c81697ddafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "columns_to_drop = [0, 4, 5, 6, len(simulated.columns) - 1]  # 0-based index of columns to drop\n",
    "simulated = simulated.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e96e2d-dc3e-4843-9ce0-67992d0c8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the first 3 columns as datetime\n",
    "simulated['date'] = pd.to_datetime(simulated.iloc[:, :3].astype(str).agg('-'.join, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763f37e-78aa-4ff2-ba79-d8e09be7858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the new 'date' column as the index\n",
    "simulated.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc12acd-26d8-4f9c-941a-cd1d0ce79b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original three columns\n",
    "simulated = simulated.drop(simulated.columns[:3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf36d7e9-9836-4160-940a-4e746f75fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows within the specified year ranges\n",
    "cal_simulated_filtered = pd.concat([simulated.loc[start_date:end_date] for start_date, end_date in calibration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dba548-a0ec-44bf-a071-54560f16110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows within the specified year ranges\n",
    "val_simulated_filtered = pd.concat([simulated.loc[start_date:end_date] for start_date, end_date in validation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51cc64-dce4-4515-ac72-b57d373d4c62",
   "metadata": {},
   "source": [
    "### Read infilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e26d8-ff13-4bf3-a239-5c80757efaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read space-separated file into DataFrame, skipping 28 rows\n",
    "infill = pd.read_csv('./infill_sf_data', sep=' ', skiprows=23, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73664d-0e46-4a13-b9ef-c37c02cc1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "columns_to_drop = [3, 4, 5]  # 0-based index of columns to drop\n",
    "infill = infill.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa80e10-7288-426f-b80c-3bb618f1dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the first 3 columns as datetime\n",
    "infill['date'] = pd.to_datetime(infill.iloc[:, :3].astype(str).agg('-'.join, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93032484-30bc-4841-8e6a-0bea5b61e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the new 'date' column as the index\n",
    "infill.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91bee5-39ef-4313-a94b-97ba959e9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original three columns\n",
    "drop = [0, 1, 2]  # 0-based index of columns to drop\n",
    "infill = infill.drop(columns=drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f99229-8c14-4e5f-88e2-1a3374b5595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows within the specified year ranges\n",
    "cal_infill_filtered = pd.concat([infill.loc[start_date:end_date] for start_date, end_date in calibration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c58a3e-a5f0-4f59-ab50-64b7149f4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows within the specified year ranges\n",
    "val_infill_filtered = pd.concat([infill.loc[start_date:end_date] for start_date, end_date in validation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66340f42-d542-4dc0-acf9-9575de3faaeb",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce3486-aab5-4649-b1d1-7bc7dccf58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_index in range(0, 14):  \n",
    "    # Extract the simulated and observed arrays\n",
    "    simulated_array1 = cal_simulated_filtered.iloc[:, column_index].values\n",
    "    observed_array1 = cal_infill_filtered.iloc[:, column_index].values\n",
    "\n",
    "    # Remove invalid values (-9999) after concatenating arrays\n",
    "    simulated_array1, observed_array1 = remove_invalid_values(simulated_array1, observed_array1)\n",
    "\n",
    "    # Check for and remove rows with nan\n",
    "    simulated_array1, observed_array1 = remove_nan_rows(simulated_array1, observed_array1)\n",
    "\n",
    "    # Check if both arrays have the same length\n",
    "    if len(observed_array1) != len(simulated_array1):\n",
    "        raise ValueError(\"Observed and simulated data arrays have different lengths!\")\n",
    "\n",
    "    # Calculate KGE for the specified pair of columns\n",
    "    total_kge = compute_kge(simulated_array1, observed_array1)\n",
    "    \n",
    "    cal_bias= compute_bias(simulated_array1, observed_array1)\n",
    "\n",
    "    # Save total KGE to the list\n",
    "    calibrate_kge.append(total_kge)\n",
    "    \n",
    "    calibrate_bias.append(cal_bias)\n",
    "\n",
    "    # Extract the simulated and observed arrays\n",
    "    simulated_array2 = val_simulated_filtered.iloc[:, column_index].values\n",
    "    observed_array2 = val_infill_filtered.iloc[:, column_index].values\n",
    "\n",
    "    # Remove invalid values (-9999) after concatenating arrays\n",
    "    simulated_array2, observed_array2 = remove_invalid_values(simulated_array2, observed_array2)\n",
    "\n",
    "    # Check for and remove rows with nan\n",
    "    simulated_array2, observed_array2 = remove_nan_rows(simulated_array2, observed_array2)\n",
    "\n",
    "    # Check if both arrays have the same length\n",
    "    if len(observed_array2) != len(simulated_array2):\n",
    "        raise ValueError(\"Observed and simulated data arrays have different lengths!\")\n",
    "\n",
    "    # Calculate KGE for the specified pair of columns\n",
    "    val_kge = compute_kge(simulated_array2, observed_array2)\n",
    "    \n",
    "    val_bias = compute_bias(simulated_array2, observed_array2)\n",
    "\n",
    "    # Save total KGE to the list\n",
    "    validate_kge.append(val_kge)\n",
    "    \n",
    "    validate_bias.append(val_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0afe9e-cb31-4f7f-865d-224a3cd87fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_names= ['Swiftcurrent Creek at Sherburne Reservoir','St. Mary River near Babb, MT',\n",
    "              'St. Mary River at International Boundary', 'Milk River at Western Crossing of International Boundary',\n",
    "              'North Fork Milk River above St Mary Canal near Browning','Milk River at Eastern Crossing',\n",
    "              'Big Sandy Creek at Mouth','Clear Creek at Mouth','Lodge Creek at International Boundary',\n",
    "              'Battle Creek at International Boundary','Peoples Creek at Mouth',\n",
    "              'Frenchman River at International Boundary', 'Beaver Creek Bowdoin','Rock Creek at Mouth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e078df5-85ec-494b-b3f8-81f15b6254b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(index=gauge_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c43d0e-5127-4a5e-bea4-56afa7ba97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Populate the 'Cal KGE' column with calibrate_kge array\n",
    "results['Cal KGE'] = calibrate_kge\n",
    "\n",
    "# Populate the 'Val KGE' column with validate_kge array\n",
    "results['Val KGE'] = validate_kge\n",
    "\n",
    "results['Cal Bias'] = calibrate_bias\n",
    "\n",
    "results['Val Bias'] = validate_bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76edf1d-ecf7-49b5-84c0-6d1b23eee5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01845b-2832-4139-82ea-379bca9fb6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "results.to_csv('../model/plots/performance_metrics.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141f141-df29-4325-b792-cb4d5724e83e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Hydrograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee481e24-8654-424f-be5e-1f109a317a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting columns 1 and 2 against the index\n",
    "column_plot = 9\n",
    "\n",
    "column_name_1 = simulated.columns[column_plot]\n",
    "column_name_2 = infill.columns[column_plot]\n",
    "\n",
    "# Replace any value of -9999 in column_name_2 with 0\n",
    "infill[column_name_2].replace(-9999, 0, inplace=True)\n",
    "\n",
    "# Plotting columns 1 and 2 against the index with no markers\n",
    "plt.figure(figsize=(16, 10))  # Adjust the figure size as needed\n",
    "plt.plot(simulated.index, simulated[column_name_1], linestyle='-', linewidth=1, label='Simulated')\n",
    "plt.plot(infill.index, infill[column_name_2], linestyle='-', linewidth=1, label='Observed')\n",
    "\n",
    "# Set x-axis limits to trim by dates\n",
    "start_date = datetime.datetime(1980, 1, 1)\n",
    "end_date = datetime.datetime(2015, 12, 31)\n",
    "plt.xlim(start_date, end_date)\n",
    "\n",
    "# Adjusting y-axis limits to make the scale smaller\n",
    "# plt.ylim(0, 10000)  # Adjust the limits as needed\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Flow (cfs)')\n",
    "plt.title('Battle Creek at International Boundary')\n",
    "\n",
    "# Add minor ticks to the x-axis (every month)\n",
    "plt.gca().xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "\n",
    "# Tilt the x labels by 45 degrees and label every year\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "\n",
    "# Move the legend to the top left\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Add KGE value as a new plot element\n",
    "kge_text = 'Calibration KGE=-1.58\\nValidation KGE= -4.61'\n",
    "plt.gcf().text(0.75, 0.85, kge_text, fontsize=12, bbox=dict(facecolor='white', alpha=0.7), verticalalignment='top')\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('../model/plots/btcib.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec7d316-2abb-4a48-a1ed-d0c3f5983557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
