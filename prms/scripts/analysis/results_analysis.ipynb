{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe3f683-4f41-4ce4-a3eb-9f2962c4440f",
   "metadata": {},
   "source": [
    "Note: make top line #!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370a9097-0137-4ef9-8a79-37ae07fffe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b9a899-e831-4463-83b0-9fbad3ae79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_adj(array: np.ndarray, dataframe: pd.DataFrame):\n",
    "    # Iterate through columns in the DataFrame\n",
    "    for column_name in dataframe.columns:\n",
    "        # Find the column name in the array\n",
    "        start_index = np.where(array == column_name)[0]\n",
    "\n",
    "        if len(start_index) == 0:\n",
    "            print(f\"Target string '{column_name}' not found in the array.\")\n",
    "            continue\n",
    "\n",
    "        start_index = start_index[0]\n",
    "\n",
    "        # Find the index of the next '####'\n",
    "        end_index = np.where(array == '####')[0]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[np.where(end_index > start_index)]\n",
    "\n",
    "        if len(end_index) == 0:\n",
    "            print(\"No '####' found after the target string.\")\n",
    "            continue\n",
    "\n",
    "        end_index = end_index[0]\n",
    "\n",
    "        # Skip the first 5 lines for nmonths\n",
    "        start_index += 6\n",
    "\n",
    "        # Save the range between start and end index to a NumPy array\n",
    "        result_array = np.arange(start_index, end_index + 1)\n",
    "\n",
    "        # Iterate through rows in the DataFrame\n",
    "        for row_index in dataframe.index:\n",
    "            # Map row_index to the corresponding index in result_array\n",
    "            index_to_update = (row_index - 1) * 12\n",
    "\n",
    "            if index_to_update < 0 or index_to_update + 11 >= len(array):\n",
    "                print(f\"Index value '{row_index}' is out of range for '{column_name}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Convert the array values to numeric before performing multiplication\n",
    "            array_values_numeric = pd.to_numeric(array[result_array[index_to_update:index_to_update + 12]])\n",
    "\n",
    "            # Perform updates by multiplying the array value by the corresponding one in the DataFrame\n",
    "            for i in range(12):\n",
    "                array[result_array[index_to_update + i]] = array_values_numeric[i] * dataframe.at[row_index, column_name]\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec8bd85-f21c-451b-aa34-deace0db9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_values(simulated, observed):\n",
    "    valid_indices = np.where((observed != -9999) & (simulated != -9999))\n",
    "    return simulated[valid_indices], observed[valid_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc825dd9-79bb-4bb7-94d3-998dac5c3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(\n",
    "    array1: np.ndarray, \n",
    "    array2: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Removes rows from two arrays where either array has NaN values.\n",
    "    Retains the first row if it doesn't have any NaN values.\n",
    "    \n",
    "    Arguments:\n",
    "    array1: np.ndarray:\n",
    "        First input array\n",
    "    array2: np.ndarray\n",
    "        Second input array\n",
    "    \n",
    "    Returns:\n",
    "    cleaned_array1: : np.ndarray\n",
    "        Cleaned array1 without NaN rows\n",
    "    cleaned_array2: np.ndarray\n",
    "        Cleaned array2 without NaN rows\n",
    "    \"\"\"\n",
    "    # checks for and removes any rows where either array has a value of NaN at a corresponding row \n",
    "    # including the first one\n",
    "    \n",
    "    mask = np.logical_and(~np.isnan(array1), ~np.isnan(array2))\n",
    "    if not np.isnan(array1[0]) and not np.isnan(array2[0]):\n",
    "        mask[0] = True\n",
    "    cleaned_array1 = array1[mask]\n",
    "    cleaned_array2 = array2[mask]\n",
    "    return cleaned_array1, cleaned_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74232359-b57b-41ff-a199-b8ed30fe03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kge(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes KGE (Kling-Gupta Efficiency) between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: KGE value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_coefficient = np.corrcoef(observed_array, simulated_array)[0, 1]\n",
    "    \n",
    "    # Calculate standard deviation ratio\n",
    "    std_observed = np.std(observed_array)\n",
    "    std_simulated = np.std(simulated_array)\n",
    "    std_ratio = std_simulated / std_observed\n",
    "    \n",
    "    # Calculate bias ratio\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    bias_ratio = mean_simulated / mean_observed\n",
    "    \n",
    "    # Calculate KGE\n",
    "    kge = 1 - np.sqrt((correlation_coefficient - 1)**2 + (std_ratio - 1)**2 + (bias_ratio - 1)**2)\n",
    "    return kge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c22918-f3ac-4b99-ba9e-ce8feb9250c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes bias between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: Bias value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate mean bias\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    \n",
    "    # Calculate bias\n",
    "    bias = mean_simulated - mean_observed\n",
    "       \n",
    "    # Calculate percent bias\n",
    "    percent_bias = (bias / mean_observed) * 100\n",
    "    \n",
    "    return percent_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e5afe9-4b80-4200-ad7c-e1f94dadf5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where your executable is located\n",
    "executable_directory = '../../model/opt_prms/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe7d79c-f146-42b3-9bc1-95476b872ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the current working directory to the specified directory\n",
    "os.chdir(executable_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad59377-0ca9-45a3-8a4d-d6310396f433",
   "metadata": {},
   "source": [
    "# run prms\n",
    "subprocess.run(['./prms', '-C./control.default.bandit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b90ac-b60d-4129-8d92-30ff1de13a1c",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "557682c4-6132-41d6-b1b1-5e5a3e4b856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store total KGE values for each file\n",
    "calibrate_kge  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dadd457-87fa-4aff-87ef-c3412c58aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_kge= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "206b969d-4d3f-467d-b994-9ad2b5d266e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate_bias= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86004c29-abdc-4617-82e8-8b8b3fad4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_bias= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fff358a-f529-4a8a-b0b2-ee9f1125ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e37571b6-5cfc-47df-b50d-19b371bef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = [('1981-01-01', '1984-12-31'),\n",
    "               ('1990-01-01', '1998-12-31'),\n",
    "               ('2004-01-01', '2007-12-31'),\n",
    "               ('2013-01-01', '2015-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b5cc19-a2bc-4a2e-b576-3b906122287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = [('1985-01-01', '1989-12-31'),\n",
    "               ('1999-01-01', '2003-12-31'),\n",
    "               ('2008-01-01', '2012-12-31')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc178a5-32f2-4ee0-9482-4f6cbb525292",
   "metadata": {},
   "source": [
    "### Read statvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2b3ae68-3d6f-4380-90e6-d1c4fc8553b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Read space-separated file into DataFrame, skipping 28 rows\n",
    "simulated = pd.read_csv('./statvar.out', sep=' ', skiprows=29, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85845192-8af6-4c67-a916-c81697ddafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "columns_to_drop = [0, 4, 5, 6, len(simulated.columns) - 1]  # 0-based index of columns to drop\n",
    "simulated = simulated.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5e96e2d-dc3e-4843-9ce0-67992d0c8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the first 3 columns as datetime\n",
    "simulated['date'] = pd.to_datetime(simulated.iloc[:, :3].astype(str).agg('-'.join, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4763f37e-78aa-4ff2-ba79-d8e09be7858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the new 'date' column as the index\n",
    "simulated.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cc12acd-26d8-4f9c-941a-cd1d0ce79b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original three columns\n",
    "simulated = simulated.drop(simulated.columns[:3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf36d7e9-9836-4160-940a-4e746f75fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows within the specified year ranges\n",
    "cal_simulated_filtered = pd.concat([simulated.loc[start_date:end_date] for start_date, end_date in calibration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7dba548-a0ec-44bf-a071-54560f16110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows within the specified year ranges\n",
    "val_simulated_filtered = pd.concat([simulated.loc[start_date:end_date] for start_date, end_date in validation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51cc64-dce4-4515-ac72-b57d373d4c62",
   "metadata": {},
   "source": [
    "### Read infilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c6e26d8-ff13-4bf3-a239-5c80757efaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read space-separated file into DataFrame, skipping 28 rows\n",
    "infill = pd.read_csv('./infill_sf_data', sep=' ', skiprows=23, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd73664d-0e46-4a13-b9ef-c37c02cc1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "columns_to_drop = [3, 4, 5]  # 0-based index of columns to drop\n",
    "infill = infill.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aa80e10-7288-426f-b80c-3bb618f1dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the first 3 columns as datetime\n",
    "infill['date'] = pd.to_datetime(infill.iloc[:, :3].astype(str).agg('-'.join, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93032484-30bc-4841-8e6a-0bea5b61e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the new 'date' column as the index\n",
    "infill.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b91bee5-39ef-4313-a94b-97ba959e9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original three columns\n",
    "drop = [0, 1, 2]  # 0-based index of columns to drop\n",
    "infill = infill.drop(columns=drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1f99229-8c14-4e5f-88e2-1a3374b5595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows within the specified year ranges\n",
    "cal_infill_filtered = pd.concat([infill.loc[start_date:end_date] for start_date, end_date in calibration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5c58a3e-a5f0-4f59-ab50-64b7149f4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows within the specified year ranges\n",
    "val_infill_filtered = pd.concat([infill.loc[start_date:end_date] for start_date, end_date in validation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66340f42-d542-4dc0-acf9-9575de3faaeb",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4ce3486-aab5-4649-b1d1-7bc7dccf58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_index in range(0, 14):  \n",
    "    # Extract the simulated and observed arrays\n",
    "    simulated_array1 = cal_simulated_filtered.iloc[:, column_index].values\n",
    "    observed_array1 = cal_infill_filtered.iloc[:, column_index].values\n",
    "\n",
    "    # Remove invalid values (-9999) after concatenating arrays\n",
    "    simulated_array1, observed_array1 = remove_invalid_values(simulated_array1, observed_array1)\n",
    "\n",
    "    # Check for and remove rows with nan\n",
    "    simulated_array1, observed_array1 = remove_nan_rows(simulated_array1, observed_array1)\n",
    "\n",
    "    # Check if both arrays have the same length\n",
    "    if len(observed_array1) != len(simulated_array1):\n",
    "        raise ValueError(\"Observed and simulated data arrays have different lengths!\")\n",
    "\n",
    "    # Calculate KGE for the specified pair of columns\n",
    "    total_kge = compute_kge(simulated_array1, observed_array1)\n",
    "    \n",
    "    cal_bias= compute_bias(simulated_array1, observed_array1)\n",
    "\n",
    "    # Save total KGE to the list\n",
    "    calibrate_kge.append(total_kge)\n",
    "    \n",
    "    calibrate_bias.append(cal_bias)\n",
    "\n",
    "    # Extract the simulated and observed arrays\n",
    "    simulated_array2 = val_simulated_filtered.iloc[:, column_index].values\n",
    "    observed_array2 = val_infill_filtered.iloc[:, column_index].values\n",
    "\n",
    "    # Remove invalid values (-9999) after concatenating arrays\n",
    "    simulated_array2, observed_array2 = remove_invalid_values(simulated_array2, observed_array2)\n",
    "\n",
    "    # Check for and remove rows with nan\n",
    "    simulated_array2, observed_array2 = remove_nan_rows(simulated_array2, observed_array2)\n",
    "\n",
    "    # Check if both arrays have the same length\n",
    "    if len(observed_array2) != len(simulated_array2):\n",
    "        raise ValueError(\"Observed and simulated data arrays have different lengths!\")\n",
    "\n",
    "    # Calculate KGE for the specified pair of columns\n",
    "    val_kge = compute_kge(simulated_array2, observed_array2)\n",
    "    \n",
    "    val_bias = compute_bias(simulated_array2, observed_array2)\n",
    "\n",
    "    # Save total KGE to the list\n",
    "    validate_kge.append(val_kge)\n",
    "    \n",
    "    validate_bias.append(val_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c0afe9e-cb31-4f7f-865d-224a3cd87fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_names= ['Swiftcurrent Creek at Sherburne Reservoir','St. Mary River near Babb, MT',\n",
    "              'St. Mary River at International Boundary', 'Milk River at Western Crossing of International Boundary',\n",
    "              'North Fork Milk River above St Mary Canal near Browning','Milk River at Eastern Crossing',\n",
    "              'Big Sandy Creek at Mouth','Clear Creek at Mouth','Lodge Creek at International Boundary',\n",
    "              'Battle Creek at International Boundary','Peoples Creek at Mouth',\n",
    "              'Frenchman River at International Boundary', 'Beaver Creek Bowdoin','Rock Creek at Mouth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e078df5-85ec-494b-b3f8-81f15b6254b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(index=gauge_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89c43d0e-5127-4a5e-bea4-56afa7ba97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Populate the 'Cal KGE' column with calibrate_kge array\n",
    "results['Cal KGE'] = calibrate_kge\n",
    "\n",
    "# Populate the 'Val KGE' column with validate_kge array\n",
    "results['Val KGE'] = validate_kge\n",
    "\n",
    "results['Cal Bias'] = calibrate_bias\n",
    "\n",
    "results['Val Bias'] = validate_bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e76edf1d-ecf7-49b5-84c0-6d1b23eee5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cal KGE</th>\n",
       "      <th>Val KGE</th>\n",
       "      <th>Cal Bias</th>\n",
       "      <th>Val Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Swiftcurrent Creek at Sherburne Reservoir</th>\n",
       "      <td>0.602494</td>\n",
       "      <td>0.639409</td>\n",
       "      <td>-25.964864</td>\n",
       "      <td>-20.588382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St. Mary River near Babb, MT</th>\n",
       "      <td>0.774562</td>\n",
       "      <td>0.817145</td>\n",
       "      <td>-17.330355</td>\n",
       "      <td>-12.269446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St. Mary River at International Boundary</th>\n",
       "      <td>0.808072</td>\n",
       "      <td>0.861406</td>\n",
       "      <td>-14.306100</td>\n",
       "      <td>-7.281741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milk River at Western Crossing of International Boundary</th>\n",
       "      <td>0.647060</td>\n",
       "      <td>0.647159</td>\n",
       "      <td>5.410058</td>\n",
       "      <td>20.085010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Fork Milk River above St Mary Canal near Browning</th>\n",
       "      <td>0.626816</td>\n",
       "      <td>0.538040</td>\n",
       "      <td>-10.395460</td>\n",
       "      <td>1.707821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milk River at Eastern Crossing</th>\n",
       "      <td>0.593923</td>\n",
       "      <td>-1.144029</td>\n",
       "      <td>6.028003</td>\n",
       "      <td>78.864205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big Sandy Creek at Mouth</th>\n",
       "      <td>-0.162140</td>\n",
       "      <td>-4.613621</td>\n",
       "      <td>95.728384</td>\n",
       "      <td>338.883192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clear Creek at Mouth</th>\n",
       "      <td>-1.967690</td>\n",
       "      <td>-0.487347</td>\n",
       "      <td>85.761308</td>\n",
       "      <td>68.569049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lodge Creek at International Boundary</th>\n",
       "      <td>-0.463109</td>\n",
       "      <td>-3.226865</td>\n",
       "      <td>118.600295</td>\n",
       "      <td>380.834888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Battle Creek at International Boundary</th>\n",
       "      <td>-1.574618</td>\n",
       "      <td>-4.609802</td>\n",
       "      <td>189.456534</td>\n",
       "      <td>382.257610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peoples Creek at Mouth</th>\n",
       "      <td>-0.466655</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>56.246501</td>\n",
       "      <td>68.081578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frenchman River at International Boundary</th>\n",
       "      <td>-0.171818</td>\n",
       "      <td>-1.666123</td>\n",
       "      <td>85.930416</td>\n",
       "      <td>208.396747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beaver Creek Bowdoin</th>\n",
       "      <td>0.625551</td>\n",
       "      <td>0.370041</td>\n",
       "      <td>15.339363</td>\n",
       "      <td>32.396248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock Creek at Mouth</th>\n",
       "      <td>-1.836712</td>\n",
       "      <td>-1.730924</td>\n",
       "      <td>201.795307</td>\n",
       "      <td>226.981646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Cal KGE   Val KGE  \\\n",
       "Swiftcurrent Creek at Sherburne Reservoir           0.602494  0.639409   \n",
       "St. Mary River near Babb, MT                        0.774562  0.817145   \n",
       "St. Mary River at International Boundary            0.808072  0.861406   \n",
       "Milk River at Western Crossing of International...  0.647060  0.647159   \n",
       "North Fork Milk River above St Mary Canal near ...  0.626816  0.538040   \n",
       "Milk River at Eastern Crossing                      0.593923 -1.144029   \n",
       "Big Sandy Creek at Mouth                           -0.162140 -4.613621   \n",
       "Clear Creek at Mouth                               -1.967690 -0.487347   \n",
       "Lodge Creek at International Boundary              -0.463109 -3.226865   \n",
       "Battle Creek at International Boundary             -1.574618 -4.609802   \n",
       "Peoples Creek at Mouth                             -0.466655  0.003270   \n",
       "Frenchman River at International Boundary          -0.171818 -1.666123   \n",
       "Beaver Creek Bowdoin                                0.625551  0.370041   \n",
       "Rock Creek at Mouth                                -1.836712 -1.730924   \n",
       "\n",
       "                                                      Cal Bias    Val Bias  \n",
       "Swiftcurrent Creek at Sherburne Reservoir           -25.964864  -20.588382  \n",
       "St. Mary River near Babb, MT                        -17.330355  -12.269446  \n",
       "St. Mary River at International Boundary            -14.306100   -7.281741  \n",
       "Milk River at Western Crossing of International...    5.410058   20.085010  \n",
       "North Fork Milk River above St Mary Canal near ...  -10.395460    1.707821  \n",
       "Milk River at Eastern Crossing                        6.028003   78.864205  \n",
       "Big Sandy Creek at Mouth                             95.728384  338.883192  \n",
       "Clear Creek at Mouth                                 85.761308   68.569049  \n",
       "Lodge Creek at International Boundary               118.600295  380.834888  \n",
       "Battle Creek at International Boundary              189.456534  382.257610  \n",
       "Peoples Creek at Mouth                               56.246501   68.081578  \n",
       "Frenchman River at International Boundary            85.930416  208.396747  \n",
       "Beaver Creek Bowdoin                                 15.339363   32.396248  \n",
       "Rock Creek at Mouth                                 201.795307  226.981646  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d01845b-2832-4139-82ea-379bca9fb6b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\model\\plots'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the DataFrame to a CSV file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../model/plots/performance_metrics.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..\\model\\plots'"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "results.to_csv('../model/plots/performance_metrics.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141f141-df29-4325-b792-cb4d5724e83e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Hydrograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee481e24-8654-424f-be5e-1f109a317a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting columns 1 and 2 against the index\n",
    "column_plot = 9\n",
    "\n",
    "column_name_1 = simulated.columns[column_plot]\n",
    "column_name_2 = infill.columns[column_plot]\n",
    "\n",
    "# Replace any value of -9999 in column_name_2 with 0\n",
    "infill[column_name_2].replace(-9999, 0, inplace=True)\n",
    "\n",
    "# Plotting columns 1 and 2 against the index with no markers\n",
    "plt.figure(figsize=(16, 10))  # Adjust the figure size as needed\n",
    "plt.plot(simulated.index, simulated[column_name_1], linestyle='-', linewidth=1, label='Simulated')\n",
    "plt.plot(infill.index, infill[column_name_2], linestyle='-', linewidth=1, label='Observed')\n",
    "\n",
    "# Set x-axis limits to trim by dates\n",
    "start_date = datetime.datetime(1980, 1, 1)\n",
    "end_date = datetime.datetime(2015, 12, 31)\n",
    "plt.xlim(start_date, end_date)\n",
    "\n",
    "# Adjusting y-axis limits to make the scale smaller\n",
    "# plt.ylim(0, 10000)  # Adjust the limits as needed\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Flow (cfs)')\n",
    "plt.title('Battle Creek at International Boundary')\n",
    "\n",
    "# Add minor ticks to the x-axis (every month)\n",
    "plt.gca().xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "\n",
    "# Tilt the x labels by 45 degrees and label every year\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "\n",
    "# Move the legend to the top left\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Add KGE value as a new plot element\n",
    "kge_text = 'Calibration KGE=-1.58\\nValidation KGE= -4.61'\n",
    "plt.gcf().text(0.75, 0.85, kge_text, fontsize=12, bbox=dict(facecolor='white', alpha=0.7), verticalalignment='top')\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('../model/plots/btcib.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec7d316-2abb-4a48-a1ed-d0c3f5983557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
