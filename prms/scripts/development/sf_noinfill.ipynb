{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbf40b7-b835-46b9-9050-7000d10315a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb4d3ff-cbe8-4eff-ac43-920f13a7c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_qobs(\n",
    "    file_path: str,\n",
    "    column_index: int,\n",
    "    station_id: int\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a CSV file, process it based on a column index,\n",
    "    and save the processed data to a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the CSV file.\n",
    "    - column_index (int, optional): The index number of the column to include in the processed DataFrame.\n",
    "    - station_id (int): The station ID to be used as the name of the first column.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): The processed DataFrame containing the specified data from the CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the file_path is valid\n",
    "    try:\n",
    "        open(file_path)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File '{file_path}' not found.\")\n",
    "\n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error reading CSV file: {str(e)}\")\n",
    "        \n",
    "    # Convert the date column to datetime if not already\n",
    "    if not isinstance(df.iloc[:, 0], pd.DatetimeIndex):\n",
    "        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "        \n",
    "\n",
    "    # Process the DataFrame based on column index\n",
    "    if column_index is not None:\n",
    "        df = df.iloc[:, [0, column_index]]\n",
    "        \n",
    "    # Convert flows from cfs to cms\n",
    " #   df.iloc[:, 1] = df.iloc[:, 1] * 0.0283168    # Keep as cfs for PRMS\n",
    "    \n",
    "    # Replace 0 values with '-9999'\n",
    "   # df.iloc[:, 1].replace(0, '-9999', inplace=True)\n",
    "    \n",
    "    # Set the first column as the index (column with index 0)\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    \n",
    "    # Name the index and the first column\n",
    "    df = df.rename_axis('date').rename(columns={df.columns[0]: f'{station_id}'})\n",
    "    \n",
    "    # Check and update the index range\n",
    "    expected_index = pd.date_range('1980-01-01', '2015-12-31')\n",
    "    if not df.index.equals(expected_index):\n",
    "        df = df.reindex(expected_index, fill_value=-9999)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e18517-8a59-4f61-960a-118ed169bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addto_qobs(\n",
    "    flow_file_path: str,\n",
    "    column_index: int,\n",
    "    station_id: int,\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read flow data from a CSV file and add it as a new column to the input DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The input DataFrame.\n",
    "    - flow_file_path (str): The path to the CSV file containing flow data.\n",
    "    - flow_column_index (int): The index number of the flow data column in the flow data CSV file.\n",
    "    - new_column_id (str): The ID to be used as the name of the new flow data column.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): The input DataFrame with an additional flow data column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the flow_file_path is valid\n",
    "    try:\n",
    "        open(flow_file_path)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File '{flow_file_path}' not found.\")\n",
    "\n",
    "    # Read the flow data CSV file\n",
    "    try:\n",
    "        flow_df = pd.read_csv(flow_file_path)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error reading flow data CSV file: {str(e)}\")\n",
    "        \n",
    "    # Convert the date column to datetime if not already\n",
    "    if not isinstance(flow_df.iloc[:, 0], pd.DatetimeIndex):\n",
    "        flow_df.iloc[:, 0] = pd.to_datetime(flow_df.iloc[:, 0])\n",
    "\n",
    "    # Process the DataFrame based on column index\n",
    "    if column_index is not None:\n",
    "        flow_df = flow_df.iloc[:, [0, column_index]]\n",
    "        \n",
    "    # Convert flows from cfs to cms\n",
    " #   flow_df.iloc[:, 1] = flow_df.iloc[:, 1] * 0.0283168    # Keep as cms\n",
    "    \n",
    "    # Replace 0 values with '-9999'\n",
    "  #  flow_df.iloc[:, 1].replace(0, '-9999', inplace=True)\n",
    "    \n",
    "    # Set the first column as the index (column with index 0)\n",
    "    flow_df.set_index(flow_df.columns[0], inplace=True)\n",
    "\n",
    "    \n",
    "        # Rename the flow data column based on the station ID\n",
    "    flow_df.rename(columns={flow_df.columns[0]: f'{station_id}'}, inplace=True)\n",
    "    \n",
    "    # Merge flow_df with df based on matching index (dates)\n",
    "    df = df.merge(flow_df, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "        # Check and update the index range\n",
    "    expected_index = pd.date_range('1980-01-01', '2015-12-31')\n",
    "    if not df.index.equals(expected_index):\n",
    "        df = df.reindex(expected_index, fill_value=-9999)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f638a67-49b7-470c-9e84-4b4f45f0cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path= '/home/paulc600/scratch/calprms/obsin/data/sf_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09efd877-da2e-4386-8fc8-4aa7f96189be",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs = initialize_qobs('/home/paulc600/local/Natural_flows/nat_gauges/SWCSB.csv', 4, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540a47c9-d7ba-4dc5-b122-5018f130cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/SMRBB.csv', 4, 13, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20f02aa-4452-4c8b-ab28-437820a6fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/SMRIB.csv', 4, 10, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f46d51-cc62-4afe-b3bb-0f71ec782553",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/MRWIB.csv', 4, 195, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba0f4b75-6896-4839-a054-d220f779160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/NFKMR.csv', 4, 429, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e3ad13a-4d93-4420-a406-7be27be60b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/MREIB.csv', 4, 95, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78be0640-f711-459a-b6f3-bfe9ce1feece",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/BSCMO.csv', 4, 133, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2075e617-e996-4cf0-bb08-0c467cbc3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/CLCMO.csv', 4, 212, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80996aa5-a61c-42ec-ab8a-fa4bf9b23bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/LDCIB.csv', 4, 143, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "109e1653-f7e1-4782-b5ac-da0e3ba0d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/BTCIB.csv', 4, 150, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b61e4f7-d924-4614-bb98-3d49959c98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/PPCMO.csv', 4, 205, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5816e604-f1bf-4b4e-a985-1a85fac9ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/FRRIB.csv', 4, 77, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f87f0f-e83d-4916-a63f-5cc02260514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/BCBMO.csv', 4, 115, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3a54658-2cdd-4095-8080-6b2aac4f5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs= addto_qobs('/home/paulc600/local/Natural_flows/nat_gauges/RKCMO.csv', 4, 79, qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bacb660f-980f-4a88-9e57-e18e84235ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24</th>\n",
       "      <th>13</th>\n",
       "      <th>10</th>\n",
       "      <th>195</th>\n",
       "      <th>429</th>\n",
       "      <th>95</th>\n",
       "      <th>133</th>\n",
       "      <th>212</th>\n",
       "      <th>143</th>\n",
       "      <th>150</th>\n",
       "      <th>205</th>\n",
       "      <th>77</th>\n",
       "      <th>115</th>\n",
       "      <th>79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>37.743924</td>\n",
       "      <td>115.593924</td>\n",
       "      <td>130.593924</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>139.785333</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>36.028291</td>\n",
       "      <td>113.878291</td>\n",
       "      <td>128.878291</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>131.562667</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>36.028291</td>\n",
       "      <td>111.878291</td>\n",
       "      <td>130.878291</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>123.340000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>34.312658</td>\n",
       "      <td>109.162659</td>\n",
       "      <td>116.162659</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98.672000</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>34.312658</td>\n",
       "      <td>104.162659</td>\n",
       "      <td>111.162659</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.781333</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-27</th>\n",
       "      <td>47.219559</td>\n",
       "      <td>289.219559</td>\n",
       "      <td>337.219559</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.204968035</td>\n",
       "      <td>3.446500</td>\n",
       "      <td>3.19</td>\n",
       "      <td>6.652540</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28</th>\n",
       "      <td>44.949388</td>\n",
       "      <td>274.949388</td>\n",
       "      <td>324.949388</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.230589039</td>\n",
       "      <td>3.877312</td>\n",
       "      <td>3.59</td>\n",
       "      <td>8.870053</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-29</th>\n",
       "      <td>42.981906</td>\n",
       "      <td>264.981906</td>\n",
       "      <td>302.981906</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.230589039</td>\n",
       "      <td>3.877312</td>\n",
       "      <td>3.59</td>\n",
       "      <td>8.870053</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30</th>\n",
       "      <td>43.435941</td>\n",
       "      <td>252.435940</td>\n",
       "      <td>293.435941</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.230589039</td>\n",
       "      <td>3.877312</td>\n",
       "      <td>3.59</td>\n",
       "      <td>8.870053</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>42.376527</td>\n",
       "      <td>240.376527</td>\n",
       "      <td>282.376527</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.256210043</td>\n",
       "      <td>4.308124</td>\n",
       "      <td>3.99</td>\n",
       "      <td>8.870053</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13149 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   24          13          10   195  429    95   133   212  \\\n",
       "1980-01-01  37.743924  115.593924  130.593924  35.0  0.0  35.0  0.00  0.00   \n",
       "1980-01-02  36.028291  113.878291  128.878291  35.0  0.0  35.0  0.00  0.00   \n",
       "1980-01-03  36.028291  111.878291  130.878291  35.0  0.0  35.0  0.00  0.00   \n",
       "1980-01-04  34.312658  109.162659  116.162659  32.0  0.0  32.0  0.00  0.00   \n",
       "1980-01-05  34.312658  104.162659  111.162659  28.0  0.0  28.0  0.00  0.00   \n",
       "...               ...         ...         ...   ...  ...   ...   ...   ...   \n",
       "2015-12-27  47.219559  289.219559  337.219559  28.5  0.0  28.5  2.27  1.38   \n",
       "2015-12-28  44.949388  274.949388  324.949388  29.1  0.0  29.1  2.57  1.49   \n",
       "2015-12-29  42.981906  264.981906  302.981906  29.1  0.0  29.1  2.57  1.49   \n",
       "2015-12-30  43.435941  252.435940  293.435941  28.4  0.0  28.4  2.57  1.49   \n",
       "2015-12-31  42.376527  240.376527  282.376527  27.8  0.0  27.8  2.78  1.69   \n",
       "\n",
       "                    143       150   205          77  115    79  \n",
       "1980-01-01            0  0.000000  0.00  139.785333  5.7  1.34  \n",
       "1980-01-02            0  0.000000  0.00  131.562667  5.4  1.25  \n",
       "1980-01-03            0  0.000000  0.00  123.340000  5.0  1.15  \n",
       "1980-01-04            0  0.000000  0.00   98.672000  4.7  0.86  \n",
       "1980-01-05            0  0.000000  0.00   65.781333  4.4  0.47  \n",
       "...                 ...       ...   ...         ...  ...   ...  \n",
       "2015-12-27  0.204968035  3.446500  3.19    6.652540  2.2  1.46  \n",
       "2015-12-28  0.230589039  3.877312  3.59    8.870053  2.9  1.96  \n",
       "2015-12-29  0.230589039  3.877312  3.59    8.870053  2.9  1.96  \n",
       "2015-12-30  0.230589039  3.877312  3.59    8.870053  2.9  1.96  \n",
       "2015-12-31  0.256210043  4.308124  3.99    8.870053  2.9  1.96  \n",
       "\n",
       "[13149 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd23f979-3023-4e5b-aab8-ef9fa321cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index to datetime\n",
    "qobs.index = pd.to_datetime(qobs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16dc090a-480f-4b00-af9e-a6d620b1ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write sf_data to a text file\n",
    "with open(data_file_path, 'w') as file:\n",
    "    # write header\n",
    "    custom_header = \"\"\"Created by paul NO INFILL\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Station IDs for runoff:\n",
    "// ID\n",
    "// Swiftcurrent Creek at Sherburne Reservoir\n",
    "// St. Mary River near Babb, MT\n",
    "// St. Mary River at International Boundary\n",
    "// Milk River at Western Crossing of International Boundary\n",
    "// North Fork Milk River above St Mary Canal near Browning\n",
    "// Milk River at Eastern Crossing\n",
    "// Big Sandy Creek at Mouth\n",
    "// Clear Creek at Mouth\n",
    "// Lodge Creek at International Boundary\n",
    "// Battle Creek at International Boundary\n",
    "// Peoples Creek at Mouth\n",
    "// Frenchman River at International Boundary\n",
    "// Beaver Creek Bowdoin\n",
    "// Rock Creek at Mouth\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Unit: runoff = cfs\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "\"\"\"\n",
    "    file.write(custom_header)\n",
    "    # Number of gauges\n",
    "    file.write('runoff 14\\n')\n",
    "    file.write('################################################\\n')\n",
    " \n",
    "\n",
    "    # Write data\n",
    "    for date_str, row in zip(qobs.index, qobs.itertuples(index=False)):\n",
    "            \n",
    "        # Extract year, month, and day from the Timestamp object\n",
    "        year = date_str.year\n",
    "        month = date_str.month\n",
    "        day = date_str.day\n",
    "        \n",
    "        # Create a list with year, month, day, and three zeros, followed by data\n",
    "        output_row = [year, month, day, '0', '0', '0'] + [str(val) for val in row]\n",
    "        \n",
    "        # Write the row to the file\n",
    "        file.write(' '.join(map(str, output_row)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d05b6-abfd-43ce-a6ea-98efbc6337d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac11a5-2d19-40c6-b92b-8723471f8cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easymore-env",
   "language": "python",
   "name": "easymore-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
