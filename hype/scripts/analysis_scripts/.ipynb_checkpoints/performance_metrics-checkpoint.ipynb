{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe3f683-4f41-4ce4-a3eb-9f2962c4440f",
   "metadata": {},
   "source": [
    "Note: make top line #!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370a9097-0137-4ef9-8a79-37ae07fffe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06654378-d1ce-498e-9266-d2f220cb953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here: C:\\Users\\Paul Coderre\\Documents\\github\\SMM_Models\\hype\\scripts\\analysis_scripts\n"
     ]
    }
   ],
   "source": [
    "# In[2]:\n",
    "cwd = os.getcwd()\n",
    "print(f'Here: {cwd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec8bd85-f21c-451b-aa34-deace0db9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_values(simulated, observed):\n",
    "    valid_indices = np.where((observed != -9999) & (simulated != -9999))\n",
    "    return simulated[valid_indices], observed[valid_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc825dd9-79bb-4bb7-94d3-998dac5c3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(\n",
    "    array1: np.ndarray, \n",
    "    array2: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Removes rows from two arrays where either array has NaN values.\n",
    "    Retains the first row if it doesn't have any NaN values.\n",
    "    \n",
    "    Arguments:\n",
    "    array1: np.ndarray:\n",
    "        First input array\n",
    "    array2: np.ndarray\n",
    "        Second input array\n",
    "    \n",
    "    Returns:\n",
    "    cleaned_array1: : np.ndarray\n",
    "        Cleaned array1 without NaN rows\n",
    "    cleaned_array2: np.ndarray\n",
    "        Cleaned array2 without NaN rows\n",
    "    \"\"\"\n",
    "    # checks for and removes any rows where either array has a value of NaN at a corresponding row \n",
    "    # including the first one\n",
    "    \n",
    "    mask = np.logical_and(~np.isnan(array1), ~np.isnan(array2))\n",
    "    if not np.isnan(array1[0]) and not np.isnan(array2[0]):\n",
    "        mask[0] = True\n",
    "    cleaned_array1 = array1[mask]\n",
    "    cleaned_array2 = array2[mask]\n",
    "    return cleaned_array1, cleaned_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74232359-b57b-41ff-a199-b8ed30fe03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kge(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes KGE (Kling-Gupta Efficiency) between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: KGE value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_coefficient = np.corrcoef(observed_array, simulated_array)[0, 1]\n",
    "    \n",
    "    # Calculate standard deviation ratio\n",
    "    std_observed = np.std(observed_array)\n",
    "    std_simulated = np.std(simulated_array)\n",
    "    std_ratio = std_simulated / std_observed\n",
    "    \n",
    "    # Calculate bias ratio\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    bias_ratio = mean_simulated / mean_observed\n",
    "    \n",
    "    # Calculate KGE\n",
    "    kge = 1 - np.sqrt((correlation_coefficient - 1)**2 + (std_ratio - 1)**2 + (bias_ratio - 1)**2)\n",
    "    \n",
    "    return kge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89a765c-f347-4206-aa4c-77842c606957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes bias between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: Bias value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate mean bias\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    \n",
    "    # Calculate bias\n",
    "    bias = mean_simulated - mean_observed\n",
    "       \n",
    "    # Calculate percent bias\n",
    "    percent_bias = (bias / mean_observed) * 100\n",
    "    \n",
    "    return percent_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb58cf0-efb5-40ab-a576-9998689cd64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where Hype outputs are saved\n",
    "file_path= 'C:/Users/Paul Coderre/Documents/github/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37571b6-5cfc-47df-b50d-19b371bef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_ranges = [('1981-01-01', '1984-12-31'),\n",
    "               ('1990-01-01', '1998-12-31'),\n",
    "               ('2004-01-01', '2007-12-31'),\n",
    "               ('2013-01-01', '2015-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b390f2ba-2162-4eed-9496-a8e516decb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ranges = [('1985-01-01', '1989-12-31'),\n",
    "               ('1999-01-01', '2003-12-31'),\n",
    "               ('2008-01-01', '2012-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557682c4-6132-41d6-b1b1-5e5a3e4b856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store total KGE values for each file\n",
    "calibration_kge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7e63ea0-f8e2-4825-8879-b597c319ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_kge= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d7dc95d-e547-48b5-a5fd-afe61de12113",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_bias = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2cb7d17-8a53-4c01-8e87-2d8454b6a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_bias= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fff358a-f529-4a8a-b0b2-ee9f1125ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2b3ae68-3d6f-4380-90e6-d1c4fc8553b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through files in the output directory\n",
    "for filename in os.listdir(file_path):\n",
    "    if filename.endswith(\".txt\") and filename.startswith(\"00\"):  # Process files with prefix '00' and end with '.txt'\n",
    "        filepath = os.path.join(file_path, filename)\n",
    "\n",
    "        # Create empty lists to store observed and simulated data for each year range\n",
    "        simulated_data_cal = []\n",
    "        observed_data_cal = []\n",
    "        simulated_data_val = []\n",
    "        observed_data_val = []\n",
    "        \n",
    "        # Read tab-separated file into DataFrame\n",
    "        df = pd.read_csv(filepath, sep='\\t', index_col=0)\n",
    "        df = df.iloc[1:]  # Drop the first row\n",
    "\n",
    "        # Convert the index to datetime if it's not already in datetime format\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        # Process and filter DataFrame based on calibration period\n",
    "        for start_date, end_date in calibration_ranges:\n",
    "            trimmed_df1 = df.loc[start_date:end_date]\n",
    "            simulated_data_cal.append(trimmed_df1['cout'].values.astype(float))  # Convert to float array\n",
    "            observed_data_cal.append(trimmed_df1['rout'].values.astype(float))  # Convert to float array\n",
    "            \n",
    "        # Process and filter DataFrame based on validation period\n",
    "        for start_date, end_date in validation_ranges:\n",
    "            trimmed_df2 = df.loc[start_date:end_date]\n",
    "            simulated_data_val.append(trimmed_df2['cout'].values.astype(float))  # Convert to float array\n",
    "            observed_data_val.append(trimmed_df2['rout'].values.astype(float))  # Convert to float array\n",
    "\n",
    "        # Concatenate the lists of arrays into NumPy arrays\n",
    "        simulated_array_cal = np.concatenate(simulated_data_cal)\n",
    "        observed_array_cal = np.concatenate(observed_data_cal)\n",
    "        simulated_array_val = np.concatenate(simulated_data_val)\n",
    "        observed_array_val = np.concatenate(observed_data_val)\n",
    "        \n",
    "        # Remove invalid values (-9999) after concatenating arrays\n",
    "        simulated_array_cal, observed_array_cal = remove_invalid_values(simulated_array_cal, observed_array_cal)\n",
    "        simulated_array_val, observed_array_val = remove_invalid_values(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # check for and remove rows with nan\n",
    "        simulated_array_cal, observed_array_cal= remove_nan_rows(simulated_array_cal, observed_array_cal)\n",
    "        simulated_array_val, observed_array_val= remove_nan_rows(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Check if both arrays have the same length\n",
    "        if len(simulated_array_cal) != len(observed_array_cal):\n",
    "            raise ValueError(f\"Observed and simulated data arrays for file {filename} have different lengths!\")\n",
    "            \n",
    "        # Check if both arrays have the same length\n",
    "        if len(simulated_array_val) != len(observed_array_val):\n",
    "            raise ValueError(f\"Observed and simulated data arrays for file {filename} have different lengths!\")\n",
    "\n",
    "        # Calculate KGE and bias for the current file\n",
    "        cal_kge = compute_kge(simulated_array_cal, observed_array_cal)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        calibration_kge.append(cal_kge)\n",
    "        \n",
    "        val_kge = compute_kge(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        validation_kge.append(val_kge)\n",
    "        \n",
    "        # Calculate KGE and bias for the current file\n",
    "        cal_bias= compute_bias(simulated_array_cal, observed_array_cal)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        calibration_bias.append(cal_bias)\n",
    "        \n",
    "                # Calculate KGE and bias for the current file\n",
    "        val_bias= compute_bias(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        validation_bias.append(val_bias)\n",
    "        \n",
    "        file_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab19030d-b5af-4682-b12b-50eabf8b9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided lists\n",
    "ids = [\n",
    "    '58232', '58213', '58208', '58408', '58643', '58308', \n",
    "    '58346', '58435', '58356', '58363', '58418', '58290', \n",
    "    '58328', '58292'\n",
    "]\n",
    "\n",
    "index = [\n",
    "    'Swiftcurrent Creek at Sherburne Reservoir',\n",
    "    'St. Mary River near Babb, MT',\n",
    "    'St. Mary River at International Boundary',\n",
    "    'Milk River at Western Crossing of International Boundary',\n",
    "    'North Fork Milk River above St Mary Canal near Browning',\n",
    "    'Milk River at Eastern Crossing',\n",
    "    'Big Sandy Creek at Mouth',\n",
    "    'Clear Creek at Mouth',\n",
    "    'Lodge Creek at International Boundary',\n",
    "    'Battle Creek at International Boundary',\n",
    "    'Peoples Creek at Mouth',\n",
    "    'Frenchman River at International Boundary',\n",
    "    'Beaver Creek Bowdoin',\n",
    "    'Rock Creek at Mouth'\n",
    "]\n",
    "\n",
    "# Create dictionary using zip\n",
    "index_id_dict = dict(zip(ids,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13fbe022-d900-4fdb-bf55-279f1ed3ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove leading \"00\" and trailing \".txt\"\n",
    "def clean_file_name(file_name):\n",
    "    if file_name.startswith(\"00\"):\n",
    "        file_name = file_name[2:]\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_name = file_name[:-4]\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd498859-4674-4ca3-bd4a-ae6026f4cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the list and clean file names\n",
    "cleaned_file_names = [clean_file_name(file_name) for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3210fd98-a376-4e4d-a7cf-655b763c215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list populated by the corresponding dictionary item for each string in cleaned_file_names\n",
    "mapped_list = [index_id_dict[name] for name in cleaned_file_names if name in index_id_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ac4879b-9c40-450f-b596-c72e13fd7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(mapped_list, index=cleaned_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c84890c2-8041-4869-b454-d5fe67b879e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the 'Cal KGE' column with calibrate_kge array\n",
    "results['Cal KGE'] = calibration_kge\n",
    "\n",
    "# Populate the 'Val KGE' column with validate_kge array\n",
    "results['Val KGE'] = validation_kge\n",
    "\n",
    "results['Cal Bias'] = calibration_bias\n",
    "\n",
    "results['Val Bias'] = validation_bias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf77d1e2-6e57-4717-b585-6caeade7b0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Cal KGE</th>\n",
       "      <th>Val KGE</th>\n",
       "      <th>Cal Bias</th>\n",
       "      <th>Val Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58292</th>\n",
       "      <td>Rock Creek at Mouth</td>\n",
       "      <td>-0.829399</td>\n",
       "      <td>-1.778834</td>\n",
       "      <td>123.030895</td>\n",
       "      <td>202.441525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0   Cal KGE   Val KGE    Cal Bias    Val Bias\n",
       "58292  Rock Creek at Mouth -0.829399 -1.778834  123.030895  202.441525"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f136d-4f7e-4c08-87b2-8e7ca0476d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
