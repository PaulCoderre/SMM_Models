{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe3f683-4f41-4ce4-a3eb-9f2962c4440f",
   "metadata": {},
   "source": [
    "Note: make top line #!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370a9097-0137-4ef9-8a79-37ae07fffe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06654378-d1ce-498e-9266-d2f220cb953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here: C:\\Users\\Paul Coderre\\Documents\\github\\SMM_Models\\hype\\scripts\\analysis_scripts\n"
     ]
    }
   ],
   "source": [
    "# In[2]:\n",
    "cwd = os.getcwd()\n",
    "print(f'Here: {cwd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec8bd85-f21c-451b-aa34-deace0db9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_values(simulated, observed):\n",
    "    valid_indices = np.where((observed != -9999) & (simulated != -9999))\n",
    "    return simulated[valid_indices], observed[valid_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc825dd9-79bb-4bb7-94d3-998dac5c3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(\n",
    "    array1: np.ndarray, \n",
    "    array2: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Removes rows from two arrays where either array has NaN values.\n",
    "    Retains the first row if it doesn't have any NaN values.\n",
    "    \n",
    "    Arguments:\n",
    "    array1: np.ndarray:\n",
    "        First input array\n",
    "    array2: np.ndarray\n",
    "        Second input array\n",
    "    \n",
    "    Returns:\n",
    "    cleaned_array1: : np.ndarray\n",
    "        Cleaned array1 without NaN rows\n",
    "    cleaned_array2: np.ndarray\n",
    "        Cleaned array2 without NaN rows\n",
    "    \"\"\"\n",
    "    # checks for and removes any rows where either array has a value of NaN at a corresponding row \n",
    "    # including the first one\n",
    "    \n",
    "    mask = np.logical_and(~np.isnan(array1), ~np.isnan(array2))\n",
    "    if not np.isnan(array1[0]) and not np.isnan(array2[0]):\n",
    "        mask[0] = True\n",
    "    cleaned_array1 = array1[mask]\n",
    "    cleaned_array2 = array2[mask]\n",
    "    return cleaned_array1, cleaned_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74232359-b57b-41ff-a199-b8ed30fe03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kge(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes KGE (Kling-Gupta Efficiency) between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: KGE value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_coefficient = np.corrcoef(observed_array, simulated_array)[0, 1]\n",
    "    \n",
    "    # Calculate standard deviation ratio\n",
    "    std_observed = np.std(observed_array)\n",
    "    std_simulated = np.std(simulated_array)\n",
    "    std_ratio = std_simulated / std_observed\n",
    "    \n",
    "    # Calculate bias ratio\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    bias_ratio = mean_simulated / mean_observed\n",
    "    \n",
    "    # Calculate KGE\n",
    "    kge = 1 - np.sqrt((correlation_coefficient - 1)**2 + (std_ratio - 1)**2 + (bias_ratio - 1)**2)\n",
    "    \n",
    "    return kge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89a765c-f347-4206-aa4c-77842c606957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes bias between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: Bias value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate mean bias\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    \n",
    "    # Calculate bias\n",
    "    bias = mean_simulated - mean_observed\n",
    "       \n",
    "    # Calculate percent bias\n",
    "    percent_bias = (bias / mean_observed) * 100\n",
    "    \n",
    "    return percent_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa87554-0658-4f95-a3f3-2f8638fdb950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nse(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes NSE (Nash-Sutcliffe Efficiency) between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: NSE value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the mean of the observed data\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    \n",
    "    # Calculate the numerator (sum of squared differences between observed and simulated)\n",
    "    numerator = np.sum((observed_array - simulated_array) ** 2)\n",
    "    \n",
    "    # Calculate the denominator (sum of squared differences between observed and mean observed)\n",
    "    denominator = np.sum((observed_array - mean_observed) ** 2)\n",
    "    \n",
    "    # Calculate NSE\n",
    "    nse = 1 - (numerator / denominator)\n",
    "    \n",
    "    return nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb58cf0-efb5-40ab-a576-9998689cd64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where Hype outputs are saved\n",
    "file_path= \"../../model/05_HYPE/final_hds//data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e37571b6-5cfc-47df-b50d-19b371bef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_ranges = [('1980-10-01', '1984-09-30'),\n",
    "               ('1989-10-01', '1998-09-30'),\n",
    "               ('2003-10-01', '2007-09-30'),\n",
    "               ('2012-10-01', '2015-09-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b390f2ba-2162-4eed-9496-a8e516decb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ranges = [('1984-10-01', '1989-09-30'),\n",
    "               ('1998-10-01', '2003-09-30'),\n",
    "               ('2007-10-01', '2012-09-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "557682c4-6132-41d6-b1b1-5e5a3e4b856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store total KGE values for each file\n",
    "calibration_kge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e63ea0-f8e2-4825-8879-b597c319ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_kge= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d7dc95d-e547-48b5-a5fd-afe61de12113",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_bias = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2cb7d17-8a53-4c01-8e87-2d8454b6a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_bias= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ba62a3-48e4-4f5d-ab26-05aeeef13291",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_nse= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5ab7643-8c53-4ca0-9ef7-8259f8295413",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_nse= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fff358a-f529-4a8a-b0b2-ee9f1125ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b3ae68-3d6f-4380-90e6-d1c4fc8553b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through files in the output directory\n",
    "for filename in os.listdir(file_path):\n",
    "    if filename.endswith(\".txt\") and filename.startswith(\"00\"):  # Process files with prefix '00' and end with '.txt'\n",
    "        filepath = os.path.join(file_path, filename)\n",
    "\n",
    "        # Create empty lists to store observed and simulated data for each year range\n",
    "        simulated_data_cal = []\n",
    "        observed_data_cal = []\n",
    "        simulated_data_val = []\n",
    "        observed_data_val = []\n",
    "        \n",
    "        # Read tab-separated file into DataFrame\n",
    "        df = pd.read_csv(filepath, sep='\\t', index_col=0)\n",
    "        df = df.iloc[1:]  # Drop the first row\n",
    "\n",
    "        # Convert the index to datetime if it's not already in datetime format\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        # Process and filter DataFrame based on calibration period\n",
    "        for start_date, end_date in calibration_ranges:\n",
    "            trimmed_df1 = df.loc[start_date:end_date]\n",
    "            simulated_data_cal.append(trimmed_df1['cout'].values.astype(float))  # Convert to float array\n",
    "            observed_data_cal.append(trimmed_df1['rout'].values.astype(float))  # Convert to float array\n",
    "            \n",
    "        # Process and filter DataFrame based on validation period\n",
    "        for start_date, end_date in validation_ranges:\n",
    "            trimmed_df2 = df.loc[start_date:end_date]\n",
    "            simulated_data_val.append(trimmed_df2['cout'].values.astype(float))  # Convert to float array\n",
    "            observed_data_val.append(trimmed_df2['rout'].values.astype(float))  # Convert to float array\n",
    "\n",
    "        # Concatenate the lists of arrays into NumPy arrays\n",
    "        simulated_array_cal = np.concatenate(simulated_data_cal)\n",
    "        observed_array_cal = np.concatenate(observed_data_cal)\n",
    "        simulated_array_val = np.concatenate(simulated_data_val)\n",
    "        observed_array_val = np.concatenate(observed_data_val)\n",
    "        \n",
    "        # Remove invalid values (-9999) after concatenating arrays\n",
    "        simulated_array_cal, observed_array_cal = remove_invalid_values(simulated_array_cal, observed_array_cal)\n",
    "        simulated_array_val, observed_array_val = remove_invalid_values(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # check for and remove rows with nan\n",
    "        simulated_array_cal, observed_array_cal= remove_nan_rows(simulated_array_cal, observed_array_cal)\n",
    "        simulated_array_val, observed_array_val= remove_nan_rows(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Check if both arrays have the same length\n",
    "        if len(simulated_array_cal) != len(observed_array_cal):\n",
    "            raise ValueError(f\"Observed and simulated data arrays for file {filename} have different lengths!\")\n",
    "            \n",
    "        # Check if both arrays have the same length\n",
    "        if len(simulated_array_val) != len(observed_array_val):\n",
    "            raise ValueError(f\"Observed and simulated data arrays for file {filename} have different lengths!\")\n",
    "\n",
    "        # Calculate KGE and bias for the current file\n",
    "        cal_kge = compute_kge(simulated_array_cal, observed_array_cal)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        calibration_kge.append(cal_kge)\n",
    "        \n",
    "        val_kge = compute_kge(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        validation_kge.append(val_kge)\n",
    "        \n",
    "        # Calculate KGE and bias for the current file\n",
    "        cal_bias= compute_bias(simulated_array_cal, observed_array_cal)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        calibration_bias.append(cal_bias)\n",
    "        \n",
    "        # Calculate KGE and bias for the current file\n",
    "        val_bias= compute_bias(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        validation_bias.append(val_bias)\n",
    "        \n",
    "               # Calculate KGE and bias for the current file\n",
    "        cal_nse= compute_nse(simulated_array_cal, observed_array_cal)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        calibration_nse.append(cal_nse)\n",
    "        \n",
    "        # Calculate KGE and bias for the current file\n",
    "        val_nse= compute_nse(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        validation_nse.append(val_nse)\n",
    "        \n",
    "        \n",
    "        file_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab19030d-b5af-4682-b12b-50eabf8b9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided lists\n",
    "ids = [\n",
    "    '58223', '58213', '58208', '58408', '58643', '58308', \n",
    "    '58346', '58425', '58356', '58363', '58418', '58290', \n",
    "    '58328', '58398'\n",
    "]\n",
    "\n",
    "index = [\n",
    "    'Swiftcurrent Creek at Sherburne Reservoir',\n",
    "    'St. Mary River near Babb, MT',\n",
    "    'St. Mary River at International Boundary',\n",
    "    'Milk River at Western Crossing of International Boundary',\n",
    "    'North Fork Milk River above St Mary Canal near Browning',\n",
    "    'Milk River at Eastern Crossing',\n",
    "    'Big Sandy Creek at Mouth',\n",
    "    'Clear Creek at Mouth',\n",
    "    'Lodge Creek at International Boundary',\n",
    "    'Battle Creek at International Boundary',\n",
    "    'Peoples Creek at Mouth',\n",
    "    'Frenchman River at International Boundary',\n",
    "    'Beaver Creek Bowdoin',\n",
    "    'Rock Creek at Mouth'\n",
    "]\n",
    "\n",
    "# Create dictionary using zip\n",
    "index_id_dict = dict(zip(ids,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13fbe022-d900-4fdb-bf55-279f1ed3ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove leading \"00\" and trailing \".txt\"\n",
    "def clean_file_name(file_name):\n",
    "    if file_name.startswith(\"00\"):\n",
    "        file_name = file_name[2:]\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_name = file_name[:-4]\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd498859-4674-4ca3-bd4a-ae6026f4cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the list and clean file names\n",
    "cleaned_file_names = [clean_file_name(file_name) for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3210fd98-a376-4e4d-a7cf-655b763c215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list populated by the corresponding dictionary item for each string in cleaned_file_names\n",
    "mapped_list = [index_id_dict[name] for name in cleaned_file_names if name in index_id_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ac4879b-9c40-450f-b596-c72e13fd7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(mapped_list, index=cleaned_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c98c68a2-03af-48f0-a9b7-58a388e266c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column 'name' to 'Name'\n",
    "results = results.rename(columns={0: 'Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c84890c2-8041-4869-b454-d5fe67b879e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the 'Cal KGE' column with calibrate_kge array\n",
    "results['Cal KGE'] = calibration_kge\n",
    "\n",
    "# Populate the 'Val KGE' column with validate_kge array\n",
    "results['Val KGE'] = validation_kge\n",
    "\n",
    "results['Cal Bias'] = calibration_bias\n",
    "\n",
    "results['Val Bias'] = validation_bias\n",
    "\n",
    "results['Cal NSE'] = calibration_nse\n",
    "\n",
    "results['Val NSE'] = validation_nse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "849b4873-ef9f-4a7e-b6e7-2d96f9b26ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to integer\n",
    "results.index = results.index.astype(int)\n",
    "\n",
    "# Sort by index in descending order\n",
    "results = results.sort_index(ascending=False)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "results.to_csv('../../model/05_HYPE/hds_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf77d1e2-6e57-4717-b585-6caeade7b0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Cal KGE</th>\n",
       "      <th>Val KGE</th>\n",
       "      <th>Cal Bias</th>\n",
       "      <th>Val Bias</th>\n",
       "      <th>Cal NSE</th>\n",
       "      <th>Val NSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58643</th>\n",
       "      <td>North Fork Milk River above St Mary Canal near...</td>\n",
       "      <td>0.286199</td>\n",
       "      <td>0.310052</td>\n",
       "      <td>-51.883043</td>\n",
       "      <td>-36.438400</td>\n",
       "      <td>-0.314972</td>\n",
       "      <td>-0.480949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58425</th>\n",
       "      <td>Clear Creek at Mouth</td>\n",
       "      <td>0.690472</td>\n",
       "      <td>0.511020</td>\n",
       "      <td>-25.354105</td>\n",
       "      <td>-19.144856</td>\n",
       "      <td>0.758409</td>\n",
       "      <td>0.367657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58418</th>\n",
       "      <td>Peoples Creek at Mouth</td>\n",
       "      <td>0.406412</td>\n",
       "      <td>0.545548</td>\n",
       "      <td>3.812925</td>\n",
       "      <td>24.719244</td>\n",
       "      <td>0.128593</td>\n",
       "      <td>0.605077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58408</th>\n",
       "      <td>Milk River at Western Crossing of Internationa...</td>\n",
       "      <td>0.544844</td>\n",
       "      <td>0.577984</td>\n",
       "      <td>1.668220</td>\n",
       "      <td>6.772194</td>\n",
       "      <td>-0.015160</td>\n",
       "      <td>0.234834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58398</th>\n",
       "      <td>Rock Creek at Mouth</td>\n",
       "      <td>0.203010</td>\n",
       "      <td>0.020936</td>\n",
       "      <td>21.794915</td>\n",
       "      <td>45.060815</td>\n",
       "      <td>-0.983475</td>\n",
       "      <td>-1.389560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58363</th>\n",
       "      <td>Battle Creek at International Boundary</td>\n",
       "      <td>0.517650</td>\n",
       "      <td>-0.392418</td>\n",
       "      <td>0.108267</td>\n",
       "      <td>103.580062</td>\n",
       "      <td>0.217420</td>\n",
       "      <td>-1.462729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58356</th>\n",
       "      <td>Lodge Creek at International Boundary</td>\n",
       "      <td>0.488120</td>\n",
       "      <td>-0.779992</td>\n",
       "      <td>13.279409</td>\n",
       "      <td>162.623199</td>\n",
       "      <td>0.224580</td>\n",
       "      <td>-0.878904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58346</th>\n",
       "      <td>Big Sandy Creek at Mouth</td>\n",
       "      <td>0.642192</td>\n",
       "      <td>0.314876</td>\n",
       "      <td>6.366256</td>\n",
       "      <td>53.193351</td>\n",
       "      <td>0.264980</td>\n",
       "      <td>0.004391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58328</th>\n",
       "      <td>Beaver Creek Bowdoin</td>\n",
       "      <td>0.610343</td>\n",
       "      <td>0.491604</td>\n",
       "      <td>-6.108400</td>\n",
       "      <td>2.200580</td>\n",
       "      <td>0.235243</td>\n",
       "      <td>0.294955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58308</th>\n",
       "      <td>Milk River at Eastern Crossing</td>\n",
       "      <td>0.407109</td>\n",
       "      <td>0.632053</td>\n",
       "      <td>-24.881619</td>\n",
       "      <td>9.136978</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.232586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58290</th>\n",
       "      <td>Frenchman River at International Boundary</td>\n",
       "      <td>0.518285</td>\n",
       "      <td>-0.097149</td>\n",
       "      <td>-16.061025</td>\n",
       "      <td>71.771786</td>\n",
       "      <td>0.317911</td>\n",
       "      <td>-1.250834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58223</th>\n",
       "      <td>Swiftcurrent Creek at Sherburne Reservoir</td>\n",
       "      <td>0.553852</td>\n",
       "      <td>0.627445</td>\n",
       "      <td>-39.021327</td>\n",
       "      <td>-33.652941</td>\n",
       "      <td>0.527956</td>\n",
       "      <td>0.632868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58213</th>\n",
       "      <td>St. Mary River near Babb, MT</td>\n",
       "      <td>0.634142</td>\n",
       "      <td>0.689532</td>\n",
       "      <td>-33.655449</td>\n",
       "      <td>-28.912348</td>\n",
       "      <td>0.670362</td>\n",
       "      <td>0.747507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58208</th>\n",
       "      <td>St. Mary River at International Boundary</td>\n",
       "      <td>0.706364</td>\n",
       "      <td>0.773375</td>\n",
       "      <td>-27.380502</td>\n",
       "      <td>-21.007684</td>\n",
       "      <td>0.741194</td>\n",
       "      <td>0.803764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Name   Cal KGE   Val KGE  \\\n",
       "58643  North Fork Milk River above St Mary Canal near...  0.286199  0.310052   \n",
       "58425                               Clear Creek at Mouth  0.690472  0.511020   \n",
       "58418                             Peoples Creek at Mouth  0.406412  0.545548   \n",
       "58408  Milk River at Western Crossing of Internationa...  0.544844  0.577984   \n",
       "58398                                Rock Creek at Mouth  0.203010  0.020936   \n",
       "58363             Battle Creek at International Boundary  0.517650 -0.392418   \n",
       "58356              Lodge Creek at International Boundary  0.488120 -0.779992   \n",
       "58346                           Big Sandy Creek at Mouth  0.642192  0.314876   \n",
       "58328                               Beaver Creek Bowdoin  0.610343  0.491604   \n",
       "58308                     Milk River at Eastern Crossing  0.407109  0.632053   \n",
       "58290          Frenchman River at International Boundary  0.518285 -0.097149   \n",
       "58223          Swiftcurrent Creek at Sherburne Reservoir  0.553852  0.627445   \n",
       "58213                       St. Mary River near Babb, MT  0.634142  0.689532   \n",
       "58208           St. Mary River at International Boundary  0.706364  0.773375   \n",
       "\n",
       "        Cal Bias    Val Bias   Cal NSE   Val NSE  \n",
       "58643 -51.883043  -36.438400 -0.314972 -0.480949  \n",
       "58425 -25.354105  -19.144856  0.758409  0.367657  \n",
       "58418   3.812925   24.719244  0.128593  0.605077  \n",
       "58408   1.668220    6.772194 -0.015160  0.234834  \n",
       "58398  21.794915   45.060815 -0.983475 -1.389560  \n",
       "58363   0.108267  103.580062  0.217420 -1.462729  \n",
       "58356  13.279409  162.623199  0.224580 -0.878904  \n",
       "58346   6.366256   53.193351  0.264980  0.004391  \n",
       "58328  -6.108400    2.200580  0.235243  0.294955  \n",
       "58308 -24.881619    9.136978  0.022995  0.232586  \n",
       "58290 -16.061025   71.771786  0.317911 -1.250834  \n",
       "58223 -39.021327  -33.652941  0.527956  0.632868  \n",
       "58213 -33.655449  -28.912348  0.670362  0.747507  \n",
       "58208 -27.380502  -21.007684  0.741194  0.803764  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e6f136d-4f7e-4c08-87b2-8e7ca0476d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmary = results.loc[[58213, 58223, 58208]]\n",
    "milk = results.loc[[58408, 58643, 58308, 58346, 58425, 58356, 58363, 58418, 58290, 58328, 58398]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "282647e0-7ba3-434f-af6c-ea36d13c8cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Basin Calibration period KGE = 0.5149282191073093\n",
      "Mean Basin Validation period KGE = 0.3017761644473157\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Basin Calibration period KGE = {results[\"Cal KGE\"].mean()}')\n",
    "print(f'Mean Basin Validation period KGE = {results[\"Val KGE\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "030c14d7-50f8-4942-b8a9-976f2d41eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean St. Mary Calibration period KGE = 0.6314524654526522\n",
      "Mean St. Mary Validation period KGE = 0.6967839259798265\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean St. Mary Calibration period KGE = {stmary[\"Cal KGE\"].mean()}')\n",
    "print(f'Mean St. Mary Validation period KGE = {stmary[\"Val KGE\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "447ff197-dfe8-4e13-8e1f-7327e939014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Milk Calibration period KGE = 0.48314887919494304\n",
      "Mean Milk Validation period KGE = 0.19404677493844905\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Milk Calibration period KGE = {milk[\"Cal KGE\"].mean()}')\n",
    "print(f'Mean Milk Validation period KGE = {milk[\"Val KGE\"].mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
