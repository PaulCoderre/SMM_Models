{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe3f683-4f41-4ce4-a3eb-9f2962c4440f",
   "metadata": {},
   "source": [
    "Note: make top line #!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370a9097-0137-4ef9-8a79-37ae07fffe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06654378-d1ce-498e-9266-d2f220cb953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here: C:\\Users\\Paul Coderre\\Documents\\github\\SMM_Models\\hype\\scripts\\analysis_scripts\n"
     ]
    }
   ],
   "source": [
    "# In[2]:\n",
    "cwd = os.getcwd()\n",
    "print(f'Here: {cwd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec8bd85-f21c-451b-aa34-deace0db9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_values(simulated, observed):\n",
    "    valid_indices = np.where((observed != -9999) & (simulated != -9999))\n",
    "    return simulated[valid_indices], observed[valid_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc825dd9-79bb-4bb7-94d3-998dac5c3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(\n",
    "    array1: np.ndarray, \n",
    "    array2: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Removes rows from two arrays where either array has NaN values.\n",
    "    Retains the first row if it doesn't have any NaN values.\n",
    "    \n",
    "    Arguments:\n",
    "    array1: np.ndarray:\n",
    "        First input array\n",
    "    array2: np.ndarray\n",
    "        Second input array\n",
    "    \n",
    "    Returns:\n",
    "    cleaned_array1: : np.ndarray\n",
    "        Cleaned array1 without NaN rows\n",
    "    cleaned_array2: np.ndarray\n",
    "        Cleaned array2 without NaN rows\n",
    "    \"\"\"\n",
    "    # checks for and removes any rows where either array has a value of NaN at a corresponding row \n",
    "    # including the first one\n",
    "    \n",
    "    mask = np.logical_and(~np.isnan(array1), ~np.isnan(array2))\n",
    "    if not np.isnan(array1[0]) and not np.isnan(array2[0]):\n",
    "        mask[0] = True\n",
    "    cleaned_array1 = array1[mask]\n",
    "    cleaned_array2 = array2[mask]\n",
    "    return cleaned_array1, cleaned_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74232359-b57b-41ff-a199-b8ed30fe03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kge(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes KGE (Kling-Gupta Efficiency) between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: KGE value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_coefficient = np.corrcoef(observed_array, simulated_array)[0, 1]\n",
    "    \n",
    "    # Calculate standard deviation ratio\n",
    "    std_observed = np.std(observed_array)\n",
    "    std_simulated = np.std(simulated_array)\n",
    "    std_ratio = std_simulated / std_observed\n",
    "    \n",
    "    # Calculate bias ratio\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    bias_ratio = mean_simulated / mean_observed\n",
    "    \n",
    "    # Calculate KGE\n",
    "    kge = 1 - np.sqrt((correlation_coefficient - 1)**2 + (std_ratio - 1)**2 + (bias_ratio - 1)**2)\n",
    "    \n",
    "    return kge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89a765c-f347-4206-aa4c-77842c606957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes bias between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: Bias value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate mean bias\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    \n",
    "    # Calculate bias\n",
    "    bias = mean_simulated - mean_observed\n",
    "       \n",
    "    # Calculate percent bias\n",
    "    percent_bias = (bias / mean_observed) * 100\n",
    "    \n",
    "    return percent_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa87554-0658-4f95-a3f3-2f8638fdb950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nse(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes NSE (Nash-Sutcliffe Efficiency) between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: NSE value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the mean of the observed data\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    \n",
    "    # Calculate the numerator (sum of squared differences between observed and simulated)\n",
    "    numerator = np.sum((observed_array - simulated_array) ** 2)\n",
    "    \n",
    "    # Calculate the denominator (sum of squared differences between observed and mean observed)\n",
    "    denominator = np.sum((observed_array - mean_observed) ** 2)\n",
    "    \n",
    "    # Calculate NSE\n",
    "    nse = 1 - (numerator / denominator)\n",
    "    \n",
    "    return nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb58cf0-efb5-40ab-a576-9998689cd64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where Hype outputs are saved\n",
    "file_path= \"../../model/model_versions/v_6/v_6_2/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e37571b6-5cfc-47df-b50d-19b371bef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_ranges = [('1980-10-01', '1984-09-30'),\n",
    "               ('1989-10-01', '1998-09-30'),\n",
    "               ('2003-10-01', '2007-09-30'),\n",
    "               ('2012-10-01', '2015-09-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b390f2ba-2162-4eed-9496-a8e516decb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ranges = [('1984-10-01', '1989-09-30'),\n",
    "               ('1998-10-01', '2003-09-30'),\n",
    "               ('2007-10-01', '2012-09-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "557682c4-6132-41d6-b1b1-5e5a3e4b856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store total KGE values for each file\n",
    "calibration_kge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e63ea0-f8e2-4825-8879-b597c319ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_kge= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d7dc95d-e547-48b5-a5fd-afe61de12113",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_bias = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2cb7d17-8a53-4c01-8e87-2d8454b6a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_bias= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ba62a3-48e4-4f5d-ab26-05aeeef13291",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_nse= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5ab7643-8c53-4ca0-9ef7-8259f8295413",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_nse= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fff358a-f529-4a8a-b0b2-ee9f1125ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b3ae68-3d6f-4380-90e6-d1c4fc8553b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through files in the output directory\n",
    "for filename in os.listdir(file_path):\n",
    "    if filename.endswith(\".txt\") and filename.startswith(\"00\"):  # Process files with prefix '00' and end with '.txt'\n",
    "        filepath = os.path.join(file_path, filename)\n",
    "\n",
    "        # Create empty lists to store observed and simulated data for each year range\n",
    "        simulated_data_cal = []\n",
    "        observed_data_cal = []\n",
    "        simulated_data_val = []\n",
    "        observed_data_val = []\n",
    "        \n",
    "        # Read tab-separated file into DataFrame\n",
    "        df = pd.read_csv(filepath, sep='\\t', index_col=0)\n",
    "        df = df.iloc[1:]  # Drop the first row\n",
    "\n",
    "        # Convert the index to datetime if it's not already in datetime format\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        # Process and filter DataFrame based on calibration period\n",
    "        for start_date, end_date in calibration_ranges:\n",
    "            trimmed_df1 = df.loc[start_date:end_date]\n",
    "            simulated_data_cal.append(trimmed_df1['cout'].values.astype(float))  # Convert to float array\n",
    "            observed_data_cal.append(trimmed_df1['rout'].values.astype(float))  # Convert to float array\n",
    "            \n",
    "        # Process and filter DataFrame based on validation period\n",
    "        for start_date, end_date in validation_ranges:\n",
    "            trimmed_df2 = df.loc[start_date:end_date]\n",
    "            simulated_data_val.append(trimmed_df2['cout'].values.astype(float))  # Convert to float array\n",
    "            observed_data_val.append(trimmed_df2['rout'].values.astype(float))  # Convert to float array\n",
    "\n",
    "        # Concatenate the lists of arrays into NumPy arrays\n",
    "        simulated_array_cal = np.concatenate(simulated_data_cal)\n",
    "        observed_array_cal = np.concatenate(observed_data_cal)\n",
    "        simulated_array_val = np.concatenate(simulated_data_val)\n",
    "        observed_array_val = np.concatenate(observed_data_val)\n",
    "        \n",
    "        # Remove invalid values (-9999) after concatenating arrays\n",
    "        simulated_array_cal, observed_array_cal = remove_invalid_values(simulated_array_cal, observed_array_cal)\n",
    "        simulated_array_val, observed_array_val = remove_invalid_values(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # check for and remove rows with nan\n",
    "        simulated_array_cal, observed_array_cal= remove_nan_rows(simulated_array_cal, observed_array_cal)\n",
    "        simulated_array_val, observed_array_val= remove_nan_rows(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Check if both arrays have the same length\n",
    "        if len(simulated_array_cal) != len(observed_array_cal):\n",
    "            raise ValueError(f\"Observed and simulated data arrays for file {filename} have different lengths!\")\n",
    "            \n",
    "        # Check if both arrays have the same length\n",
    "        if len(simulated_array_val) != len(observed_array_val):\n",
    "            raise ValueError(f\"Observed and simulated data arrays for file {filename} have different lengths!\")\n",
    "\n",
    "        # Calculate KGE and bias for the current file\n",
    "        cal_kge = compute_kge(simulated_array_cal, observed_array_cal)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        calibration_kge.append(cal_kge)\n",
    "        \n",
    "        val_kge = compute_kge(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        validation_kge.append(val_kge)\n",
    "        \n",
    "        # Calculate KGE and bias for the current file\n",
    "        cal_bias= compute_bias(simulated_array_cal, observed_array_cal)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        calibration_bias.append(cal_bias)\n",
    "        \n",
    "        # Calculate KGE and bias for the current file\n",
    "        val_bias= compute_bias(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        validation_bias.append(val_bias)\n",
    "        \n",
    "               # Calculate KGE and bias for the current file\n",
    "        cal_nse= compute_nse(simulated_array_cal, observed_array_cal)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        calibration_nse.append(cal_nse)\n",
    "        \n",
    "        # Calculate KGE and bias for the current file\n",
    "        val_nse= compute_nse(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        validation_nse.append(val_nse)\n",
    "        \n",
    "        \n",
    "        file_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab19030d-b5af-4682-b12b-50eabf8b9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_id_dict = {\n",
    "    '58643': {'Location': 'North Fork Milk River above St Mary Canal near Browning', 'Gauge ID': 'NFKMR', 'Drainage Area (km2)': 148},\n",
    "    '58425': {'Location': 'Clear Creek at Mouth', 'Gauge ID': 'CLCMO', 'Drainage Area (km2)': 351},\n",
    "    '58418': {'Location': 'Peoples Creek at Mouth', 'Gauge ID': 'PPCMO', 'Drainage Area (km2)': 1817},\n",
    "    '58408': {'Location': 'Milk River at Western Crossing of International Boundary', 'Gauge ID': 'MRWIB', 'Drainage Area (km2)': 1054},\n",
    "    '58398': {'Location': 'Rock Creek at Mouth', 'Gauge ID': 'RKCMO', 'Drainage Area (km2)': 2298},\n",
    "    '58363': {'Location': 'Battle Creek at International Boundary', 'Gauge ID': 'BTCIB', 'Drainage Area (km2)': 2120},\n",
    "    '58356': {'Location': 'Lodge Creek at International Boundary', 'Gauge ID': 'LDCIB', 'Drainage Area (km2)': 3897},\n",
    "    '58346': {'Location': 'Big Sandy Creek at Mouth', 'Gauge ID': 'BSCMO', 'Drainage Area (km2)': 4403},\n",
    "    '58328': {'Location': 'Beaver Creek Bowdoin', 'Gauge ID': 'BCHMO', 'Drainage Area (km2)': 6503},\n",
    "    '58308': {'Location': 'Milk River at Eastern Crossing', 'Gauge ID': 'MREIB', 'Drainage Area (km2)': 3393},\n",
    "    '58290': {'Location': 'Frenchman River at International Boundary', 'Gauge ID': 'FRRIB', 'Drainage Area (km2)': 5546},\n",
    "    '58223': {'Location': 'Swiftcurrent Creek at Sherburne Reservoir', 'Gauge ID': 'SWCSB', 'Drainage Area (km2)': 80},\n",
    "    '58213': {'Location': 'St. Mary River near Babb, MT', 'Gauge ID': 'SMRBB', 'Drainage Area (km2)': 711},\n",
    "    '58208': {'Location': 'St. Mary River at International Boundary', 'Gauge ID': 'SMRIB', 'Drainage Area (km2)': 1217}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13fbe022-d900-4fdb-bf55-279f1ed3ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove leading \"00\" and trailing \".txt\"\n",
    "def clean_file_name(file_name):\n",
    "    if file_name.startswith(\"00\"):\n",
    "        file_name = file_name[2:]\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_name = file_name[:-4]\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd498859-4674-4ca3-bd4a-ae6026f4cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the list and clean file names\n",
    "cleaned_file_names = [clean_file_name(file_name) for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3210fd98-a376-4e4d-a7cf-655b763c215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list populated by the corresponding dictionary item for each string in cleaned_file_names\n",
    "mapped_list = [index_id_dict[name] for name in cleaned_file_names if name in index_id_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ac4879b-9c40-450f-b596-c72e13fd7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(mapped_list, index=cleaned_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c98c68a2-03af-48f0-a9b7-58a388e266c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column 'name' to 'Name'\n",
    "results = results.rename(columns={0: 'Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c84890c2-8041-4869-b454-d5fe67b879e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add calibration period results\n",
    "\n",
    "results['Cal NSE'] = calibration_nse\n",
    "\n",
    "results['Cal KGE'] = calibration_kge\n",
    "\n",
    "results['Cal Bias'] = calibration_bias\n",
    "\n",
    "# Populate the 'Val KGE' column with validate_kge array\n",
    "\n",
    "results['Val NSE'] = validation_nse\n",
    "\n",
    "results['Val KGE'] = validation_kge\n",
    "\n",
    "results['Val Bias'] = validation_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "849b4873-ef9f-4a7e-b6e7-2d96f9b26ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to integer\n",
    "results.index = results.index.astype(int)\n",
    "\n",
    "# Sort by index in descending order\n",
    "results = results.sort_index(ascending=False)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "results.to_csv('../../model/model_versions/v_6/v_6_2/results/performance_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf77d1e2-6e57-4717-b585-6caeade7b0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Drainage Area (km2)</th>\n",
       "      <th>Cal NSE</th>\n",
       "      <th>Cal KGE</th>\n",
       "      <th>Cal Bias</th>\n",
       "      <th>Val NSE</th>\n",
       "      <th>Val KGE</th>\n",
       "      <th>Val Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58643</th>\n",
       "      <td>North Fork Milk River above St Mary Canal near...</td>\n",
       "      <td>148</td>\n",
       "      <td>0.213978</td>\n",
       "      <td>0.379196</td>\n",
       "      <td>-45.294624</td>\n",
       "      <td>-0.212959</td>\n",
       "      <td>0.383710</td>\n",
       "      <td>-35.905298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58425</th>\n",
       "      <td>Clear Creek at Mouth</td>\n",
       "      <td>351</td>\n",
       "      <td>0.831686</td>\n",
       "      <td>0.765334</td>\n",
       "      <td>15.001714</td>\n",
       "      <td>0.404716</td>\n",
       "      <td>0.519064</td>\n",
       "      <td>3.564819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58418</th>\n",
       "      <td>Peoples Creek at Mouth</td>\n",
       "      <td>1817</td>\n",
       "      <td>0.213067</td>\n",
       "      <td>0.255043</td>\n",
       "      <td>12.873638</td>\n",
       "      <td>0.459852</td>\n",
       "      <td>0.391340</td>\n",
       "      <td>15.487420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58408</th>\n",
       "      <td>Milk River at Western Crossing of Internationa...</td>\n",
       "      <td>1054</td>\n",
       "      <td>0.358931</td>\n",
       "      <td>0.488669</td>\n",
       "      <td>-4.659010</td>\n",
       "      <td>0.372787</td>\n",
       "      <td>0.454257</td>\n",
       "      <td>-3.737740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58398</th>\n",
       "      <td>Rock Creek at Mouth</td>\n",
       "      <td>2298</td>\n",
       "      <td>0.148976</td>\n",
       "      <td>0.287762</td>\n",
       "      <td>-7.294314</td>\n",
       "      <td>0.069254</td>\n",
       "      <td>0.244110</td>\n",
       "      <td>7.261184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58363</th>\n",
       "      <td>Battle Creek at International Boundary</td>\n",
       "      <td>2120</td>\n",
       "      <td>0.316495</td>\n",
       "      <td>0.324967</td>\n",
       "      <td>0.901512</td>\n",
       "      <td>-0.199505</td>\n",
       "      <td>0.080830</td>\n",
       "      <td>77.018296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58356</th>\n",
       "      <td>Lodge Creek at International Boundary</td>\n",
       "      <td>3897</td>\n",
       "      <td>0.224769</td>\n",
       "      <td>0.172799</td>\n",
       "      <td>-10.425520</td>\n",
       "      <td>0.339543</td>\n",
       "      <td>-0.061602</td>\n",
       "      <td>93.226531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58346</th>\n",
       "      <td>Big Sandy Creek at Mouth</td>\n",
       "      <td>4403</td>\n",
       "      <td>0.598116</td>\n",
       "      <td>0.595735</td>\n",
       "      <td>35.478258</td>\n",
       "      <td>0.463222</td>\n",
       "      <td>0.399952</td>\n",
       "      <td>53.417107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58328</th>\n",
       "      <td>Beaver Creek Bowdoin</td>\n",
       "      <td>6503</td>\n",
       "      <td>0.592496</td>\n",
       "      <td>0.606512</td>\n",
       "      <td>-17.396970</td>\n",
       "      <td>0.076896</td>\n",
       "      <td>0.415078</td>\n",
       "      <td>-8.984903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58308</th>\n",
       "      <td>Milk River at Eastern Crossing</td>\n",
       "      <td>3393</td>\n",
       "      <td>0.162128</td>\n",
       "      <td>0.222347</td>\n",
       "      <td>-22.955302</td>\n",
       "      <td>-0.049926</td>\n",
       "      <td>0.486183</td>\n",
       "      <td>6.727465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58290</th>\n",
       "      <td>Frenchman River at International Boundary</td>\n",
       "      <td>5546</td>\n",
       "      <td>0.386215</td>\n",
       "      <td>0.332459</td>\n",
       "      <td>-15.948489</td>\n",
       "      <td>0.023803</td>\n",
       "      <td>0.219427</td>\n",
       "      <td>56.876188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58223</th>\n",
       "      <td>Swiftcurrent Creek at Sherburne Reservoir</td>\n",
       "      <td>80</td>\n",
       "      <td>0.748237</td>\n",
       "      <td>0.692923</td>\n",
       "      <td>-23.194361</td>\n",
       "      <td>0.805807</td>\n",
       "      <td>0.781740</td>\n",
       "      <td>-17.292364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58213</th>\n",
       "      <td>St. Mary River near Babb, MT</td>\n",
       "      <td>711</td>\n",
       "      <td>0.825860</td>\n",
       "      <td>0.779904</td>\n",
       "      <td>-15.765089</td>\n",
       "      <td>0.874466</td>\n",
       "      <td>0.851229</td>\n",
       "      <td>-10.714530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58208</th>\n",
       "      <td>St. Mary River at International Boundary</td>\n",
       "      <td>1217</td>\n",
       "      <td>0.855801</td>\n",
       "      <td>0.922550</td>\n",
       "      <td>-2.832988</td>\n",
       "      <td>0.869899</td>\n",
       "      <td>0.913129</td>\n",
       "      <td>3.821542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Location  Drainage Area (km2)  \\\n",
       "58643  North Fork Milk River above St Mary Canal near...                  148   \n",
       "58425                               Clear Creek at Mouth                  351   \n",
       "58418                             Peoples Creek at Mouth                 1817   \n",
       "58408  Milk River at Western Crossing of Internationa...                 1054   \n",
       "58398                                Rock Creek at Mouth                 2298   \n",
       "58363             Battle Creek at International Boundary                 2120   \n",
       "58356              Lodge Creek at International Boundary                 3897   \n",
       "58346                           Big Sandy Creek at Mouth                 4403   \n",
       "58328                               Beaver Creek Bowdoin                 6503   \n",
       "58308                     Milk River at Eastern Crossing                 3393   \n",
       "58290          Frenchman River at International Boundary                 5546   \n",
       "58223          Swiftcurrent Creek at Sherburne Reservoir                   80   \n",
       "58213                       St. Mary River near Babb, MT                  711   \n",
       "58208           St. Mary River at International Boundary                 1217   \n",
       "\n",
       "        Cal NSE   Cal KGE   Cal Bias   Val NSE   Val KGE   Val Bias  \n",
       "58643  0.213978  0.379196 -45.294624 -0.212959  0.383710 -35.905298  \n",
       "58425  0.831686  0.765334  15.001714  0.404716  0.519064   3.564819  \n",
       "58418  0.213067  0.255043  12.873638  0.459852  0.391340  15.487420  \n",
       "58408  0.358931  0.488669  -4.659010  0.372787  0.454257  -3.737740  \n",
       "58398  0.148976  0.287762  -7.294314  0.069254  0.244110   7.261184  \n",
       "58363  0.316495  0.324967   0.901512 -0.199505  0.080830  77.018296  \n",
       "58356  0.224769  0.172799 -10.425520  0.339543 -0.061602  93.226531  \n",
       "58346  0.598116  0.595735  35.478258  0.463222  0.399952  53.417107  \n",
       "58328  0.592496  0.606512 -17.396970  0.076896  0.415078  -8.984903  \n",
       "58308  0.162128  0.222347 -22.955302 -0.049926  0.486183   6.727465  \n",
       "58290  0.386215  0.332459 -15.948489  0.023803  0.219427  56.876188  \n",
       "58223  0.748237  0.692923 -23.194361  0.805807  0.781740 -17.292364  \n",
       "58213  0.825860  0.779904 -15.765089  0.874466  0.851229 -10.714530  \n",
       "58208  0.855801  0.922550  -2.832988  0.869899  0.913129   3.821542  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e6f136d-4f7e-4c08-87b2-8e7ca0476d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmary = results.loc[[58213, 58223, 58208]]\n",
    "milk = results.loc[[58408, 58643, 58308, 58346, 58425, 58356, 58363, 58418, 58290, 58328, 58398]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "282647e0-7ba3-434f-af6c-ea36d13c8cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Basin Calibration period KGE = 0.48758577280176013\n",
      "Mean Basin Validation period KGE = 0.43417482885289055\n",
      "Mean Basin Calibration period NSE = 0.4626253763438763\n",
      "Mean Basin Validation period NSE = 0.306989727956244\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Basin Calibration period KGE = {results[\"Cal KGE\"].mean()}')\n",
    "print(f'Mean Basin Validation period KGE = {results[\"Val KGE\"].mean()}')\n",
    "\n",
    "print(f'Mean Basin Calibration period NSE = {results[\"Cal NSE\"].mean()}')\n",
    "print(f'Mean Basin Validation period NSE = {results[\"Val NSE\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "030c14d7-50f8-4942-b8a9-976f2d41eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean St. Mary Calibration period KGE = 0.7984589852746526\n",
      "Mean St. Mary Validation period KGE = 0.8486994714876928\n",
      "Mean St. Mary Calibration period NSE = 0.8099659483212287\n",
      "Mean St. Mary Validation period NSE = 0.8500576934246961\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean St. Mary Calibration period KGE = {stmary[\"Cal KGE\"].mean()}')\n",
    "print(f'Mean St. Mary Validation period KGE = {stmary[\"Val KGE\"].mean()}')\n",
    "\n",
    "print(f'Mean St. Mary Calibration period NSE = {stmary[\"Cal NSE\"].mean()}')\n",
    "print(f'Mean St. Mary Validation period NSE = {stmary[\"Val NSE\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "447ff197-dfe8-4e13-8e1f-7327e939014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Milk Calibration period KGE = 0.40280216940006214\n",
      "Mean Milk Validation period KGE = 0.32112265358885356\n",
      "Mean Milk Calibration period NSE = 0.367896129440962\n",
      "Mean Milk Validation period NSE = 0.1588802828284843\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Milk Calibration period KGE = {milk[\"Cal KGE\"].mean()}')\n",
    "print(f'Mean Milk Validation period KGE = {milk[\"Val KGE\"].mean()}')\n",
    "\n",
    "print(f'Mean Milk Calibration period NSE = {milk[\"Cal NSE\"].mean()}')\n",
    "print(f'Mean Milk Validation period NSE = {milk[\"Val NSE\"].mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
