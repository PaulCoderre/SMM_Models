{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d9a1e8-a7ba-471f-9eb9-f532cbe34479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ceadb47-23db-465d-bf7d-3e593e8eeff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_values(simulated, observed):\n",
    "    valid_indices = np.where((observed != -9999) & (simulated != -9999))\n",
    "    return simulated[valid_indices], observed[valid_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7e831e-e9c2-45ed-a363-75fae5a98a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(\n",
    "    array1: np.ndarray, \n",
    "    array2: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Removes rows from two arrays where either array has NaN values.\n",
    "    Retains the first row if it doesn't have any NaN values.\n",
    "    \n",
    "    Arguments:\n",
    "    array1: np.ndarray:\n",
    "        First input array\n",
    "    array2: np.ndarray\n",
    "        Second input array\n",
    "    \n",
    "    Returns:\n",
    "    cleaned_array1: : np.ndarray\n",
    "        Cleaned array1 without NaN rows\n",
    "    cleaned_array2: np.ndarray\n",
    "        Cleaned array2 without NaN rows\n",
    "    \"\"\"\n",
    "    # checks for and removes any rows where either array has a value of NaN at a corresponding row \n",
    "    # including the first one\n",
    "    \n",
    "    mask = np.logical_and(~np.isnan(array1), ~np.isnan(array2))\n",
    "    if not np.isnan(array1[0]) and not np.isnan(array2[0]):\n",
    "        mask[0] = True\n",
    "    cleaned_array1 = array1[mask]\n",
    "    cleaned_array2 = array2[mask]\n",
    "    return cleaned_array1, cleaned_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16772b71-a7ac-42ea-ae90-dc76efac682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kge(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes KGE (Kling-Gupta Efficiency) between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: KGE value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_coefficient = np.corrcoef(observed_array, simulated_array)[0, 1]\n",
    "    \n",
    "    # Calculate standard deviation ratio\n",
    "    std_observed = np.std(observed_array)\n",
    "    std_simulated = np.std(simulated_array)\n",
    "    std_ratio = std_simulated / std_observed\n",
    "    \n",
    "    # Calculate bias ratio\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    bias_ratio = mean_simulated / mean_observed\n",
    "    \n",
    "    # Calculate KGE\n",
    "    kge = 1 - np.sqrt((correlation_coefficient - 1)**2 + (std_ratio - 1)**2 + (bias_ratio - 1)**2)\n",
    "    \n",
    "    return kge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382dd8cd-134c-4512-abc0-8e8affc8decb",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08a5303-a59b-43a1-8804-14c989312578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where Hype outputs are saved\n",
    "file_path= \"../opt_hype/\"\n",
    "\n",
    "sim_column= 'cout'\n",
    "\n",
    "obs_column= 'rout'\n",
    "\n",
    "calibration_ranges = [('1981-01-01', '1984-12-31'),\n",
    "               ('1990-01-01', '1998-12-31'),\n",
    "               ('2004-01-01', '2007-12-31'),\n",
    "               ('2013-01-01', '2015-12-31')]\n",
    "\n",
    "validation_ranges = [('1985-01-01', '1989-12-31'),\n",
    "               ('1999-01-01', '2003-12-31'),\n",
    "               ('2008-01-01', '2012-12-31')]\n",
    "\n",
    "# Create an empty list to store total KGE values for each file\n",
    "calibration_kge = []\n",
    "\n",
    "validation_kge= []\n",
    "\n",
    "file_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f1642-afb7-4cb7-b8a3-b9b27668b0ff",
   "metadata": {},
   "source": [
    "### Calculate KGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffab89a-4894-4789-b8cf-f0b49fa163ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through files in the output directory\n",
    "for filename in os.listdir(file_path):\n",
    "    if filename.endswith(\".txt\") and filename.startswith(\"00\"):  # Process files with prefix '00' and end with '.txt'\n",
    "        filepath = os.path.join(file_path, filename)\n",
    "\n",
    "        # Create empty lists to store observed and simulated data for each year range\n",
    "        simulated_data_cal = []\n",
    "        observed_data_cal = []\n",
    "        simulated_data_val = []\n",
    "        observed_data_val = []\n",
    "        \n",
    "        # read HYPE output into dataframe\n",
    "        flow = pd.read_csv(filepath, index_col=0, sep='\\t')\n",
    "\n",
    "        # Drop the first row if it's unnecessary (e.g., metadata or headers)\n",
    "        flow = flow.drop(flow.index[0])\n",
    "\n",
    "        # Ensure the index is datetime\n",
    "        flow.index = pd.to_datetime(flow.index)\n",
    "\n",
    "        # Ensure the 'cout' and 'rout' columns are of float type\n",
    "        flow['cout'] = flow['cout'].astype(float)\n",
    "        flow['rout'] = flow['rout'].astype(float)\n",
    "\n",
    "        # Replace -9999 with NaN\n",
    "        flow.replace(-9999, np.nan, inplace=True)\n",
    "        \n",
    "        # find average annual obs\n",
    "        average_annual_obs = flow['rout'].groupby(flow.index.dayofyear).mean()\n",
    "\n",
    "        # Create a DataFrame to store the averages\n",
    "        average_annual = pd.DataFrame({\n",
    "            'obs': average_annual_obs\n",
    "        })\n",
    "\n",
    "        # Convert the day-of-year index to datetime format\n",
    "        average_annual.index = pd.to_datetime(average_annual.index, format='%j').strftime('%m-%d')\n",
    "\n",
    "        # Drop the last row\n",
    "        average_annual = average_annual.iloc[:-1]\n",
    "\n",
    "        # Extract unique years from benchmark DataFrame\n",
    "        years = flow.index.year.unique()\n",
    "\n",
    "        # Prepare a list to hold DataFrames for each year\n",
    "        merged_dfs = []\n",
    "\n",
    "        for year in years:\n",
    "            # Create a DataFrame with the year added to the month-day index\n",
    "            annual_average_year = average_annual.copy()\n",
    "            annual_average_year.index = pd.to_datetime(annual_average_year.index + f\"-{year}\", format='%m-%d-%Y')\n",
    "\n",
    "            # Filter benchmark data for the current year\n",
    "            benchmark_year = flow[flow.index.year == year]\n",
    "\n",
    "            # Merge the benchmark data with annual_average data for the current year\n",
    "            merged_year = pd.merge(benchmark_year, annual_average_year, left_index=True, right_index=True, how='left')\n",
    "\n",
    "            # Append to the list of DataFrames\n",
    "            merged_dfs.append(merged_year)\n",
    "\n",
    "        # Concatenate all DataFrames\n",
    "        result_df = pd.concat(merged_dfs)\n",
    "\n",
    "        # Rename the column for clarity\n",
    "        result_df.rename(columns={'obs': 'obs_model'}, inplace=True)\n",
    "\n",
    "        # Convert the index to datetime if it's not already in datetime format\n",
    "        if not isinstance(result_df.index, pd.DatetimeIndex):\n",
    "            result_df.index = pd.to_datetime(result_df.index)\n",
    "\n",
    "        # Process and filter DataFrame based on calibration period\n",
    "        for start_date, end_date in calibration_ranges:\n",
    "            trimmed_df1 = result_df.loc[start_date:end_date]\n",
    "            simulated_data_cal.append(trimmed_df1[sim_column].values.astype(float))  # Convert to float array\n",
    "            observed_data_cal.append(trimmed_df1[obs_column].values.astype(float))  # Convert to float array\n",
    "            \n",
    "        # Process and filter DataFrame based on validation period\n",
    "        for start_date, end_date in validation_ranges:\n",
    "            trimmed_df2 = result_df.loc[start_date:end_date]\n",
    "            simulated_data_val.append(trimmed_df2[sim_column].values.astype(float))  # Convert to float array\n",
    "            observed_data_val.append(trimmed_df2[obs_column].values.astype(float))  # Convert to float array\n",
    "\n",
    "        # Concatenate the lists of arrays into NumPy arrays\n",
    "        simulated_array_cal = np.concatenate(simulated_data_cal)\n",
    "        observed_array_cal = np.concatenate(observed_data_cal)\n",
    "        simulated_array_val = np.concatenate(simulated_data_val)\n",
    "        observed_array_val = np.concatenate(observed_data_val)\n",
    "        \n",
    "        # Remove invalid values (-9999) after concatenating arrays\n",
    "        simulated_array_cal, observed_array_cal = remove_invalid_values(simulated_array_cal, observed_array_cal)\n",
    "        simulated_array_val, observed_array_val = remove_invalid_values(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # check for and remove rows with nan\n",
    "        simulated_array_cal, observed_array_cal= remove_nan_rows(simulated_array_cal, observed_array_cal)\n",
    "        simulated_array_val, observed_array_val= remove_nan_rows(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Check if both arrays have the same length\n",
    "        if len(simulated_array_cal) != len(observed_array_cal):\n",
    "            raise ValueError(f\"Observed and simulated data arrays for file {filename} have different lengths!\")\n",
    "            \n",
    "        # Check if both arrays have the same length\n",
    "        if len(simulated_array_val) != len(observed_array_val):\n",
    "            raise ValueError(f\"Observed and simulated data arrays for file {filename} have different lengths!\")\n",
    "\n",
    "        # Calculate KGE and bias for the current file\n",
    "        cal_kge = compute_kge(simulated_array_cal, observed_array_cal)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        calibration_kge.append(cal_kge)\n",
    "        \n",
    "        val_kge = compute_kge(simulated_array_val, observed_array_val)\n",
    "        \n",
    "        # Save total KGE to the list\n",
    "        validation_kge.append(val_kge)\n",
    "        \n",
    "        file_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948ec00e-4b19-443e-9362-368e3dc4da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided lists\n",
    "ids = [\n",
    "    '58223', '58213', '58208', '58408', '58643', '58308', \n",
    "    '58346', '58425', '58356', '58363', '58418', '58290', \n",
    "    '58328', '58292'\n",
    "]\n",
    "\n",
    "index = [\n",
    "    'Swiftcurrent Creek at Sherburne Reservoir',\n",
    "    'St. Mary River near Babb, MT',\n",
    "    'St. Mary River at International Boundary',\n",
    "    'Milk River at Western Crossing of International Boundary',\n",
    "    'North Fork Milk River above St Mary Canal near Browning',\n",
    "    'Milk River at Eastern Crossing',\n",
    "    'Big Sandy Creek at Mouth',\n",
    "    'Clear Creek at Mouth',\n",
    "    'Lodge Creek at International Boundary',\n",
    "    'Battle Creek at International Boundary',\n",
    "    'Peoples Creek at Mouth',\n",
    "    'Frenchman River at International Boundary',\n",
    "    'Beaver Creek Bowdoin',\n",
    "    'Rock Creek at Mouth'\n",
    "]\n",
    "\n",
    "# Create dictionary using zip\n",
    "index_id_dict = dict(zip(ids,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b20aa63-61c1-4393-b4f7-e7554842c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove leading \"00\" and trailing \".txt\"\n",
    "def clean_file_name(file_name):\n",
    "    if file_name.startswith(\"00\"):\n",
    "        file_name = file_name[2:]\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_name = file_name[:-4]\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5dd61d0-e296-47fb-a759-4ae0835b1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the list and clean file names\n",
    "cleaned_file_names = [clean_file_name(file_name) for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6268baa8-ed3b-4466-b577-b7afd6dcdd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list populated by the corresponding dictionary item for each string in cleaned_file_names\n",
    "mapped_list = [index_id_dict[name] for name in cleaned_file_names if name in index_id_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e4a1640-969a-4369-9e97-34a4d749665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(mapped_list, index=cleaned_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b1a313f-246f-4225-8afc-2913a3241720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column 'name' to 'Name'\n",
    "results = results.rename(columns={0: 'Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d9fddac-8faf-4e7a-a700-6605738a8a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Cal KGE</th>\n",
       "      <th>Val KGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58208</th>\n",
       "      <td>St. Mary River at International Boundary</td>\n",
       "      <td>0.854694</td>\n",
       "      <td>0.863095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58213</th>\n",
       "      <td>St. Mary River near Babb, MT</td>\n",
       "      <td>0.752084</td>\n",
       "      <td>0.799242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58223</th>\n",
       "      <td>Swiftcurrent Creek at Sherburne Reservoir</td>\n",
       "      <td>0.660619</td>\n",
       "      <td>0.715382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58290</th>\n",
       "      <td>Frenchman River at International Boundary</td>\n",
       "      <td>0.332411</td>\n",
       "      <td>0.183949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58292</th>\n",
       "      <td>Rock Creek at Mouth</td>\n",
       "      <td>-0.051166</td>\n",
       "      <td>-0.999370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58308</th>\n",
       "      <td>Milk River at Eastern Crossing</td>\n",
       "      <td>0.374327</td>\n",
       "      <td>0.641805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58328</th>\n",
       "      <td>Beaver Creek Bowdoin</td>\n",
       "      <td>0.682549</td>\n",
       "      <td>0.494172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58346</th>\n",
       "      <td>Big Sandy Creek at Mouth</td>\n",
       "      <td>0.813249</td>\n",
       "      <td>0.431143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58356</th>\n",
       "      <td>Lodge Creek at International Boundary</td>\n",
       "      <td>0.436502</td>\n",
       "      <td>-0.380760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58363</th>\n",
       "      <td>Battle Creek at International Boundary</td>\n",
       "      <td>0.507260</td>\n",
       "      <td>-0.119981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58408</th>\n",
       "      <td>Milk River at Western Crossing of Internationa...</td>\n",
       "      <td>0.544777</td>\n",
       "      <td>0.492841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58418</th>\n",
       "      <td>Peoples Creek at Mouth</td>\n",
       "      <td>0.426048</td>\n",
       "      <td>0.509721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58425</th>\n",
       "      <td>Clear Creek at Mouth</td>\n",
       "      <td>0.808600</td>\n",
       "      <td>0.545935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58643</th>\n",
       "      <td>North Fork Milk River above St Mary Canal near...</td>\n",
       "      <td>0.365203</td>\n",
       "      <td>0.323074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Name   Cal KGE   Val KGE\n",
       "58208           St. Mary River at International Boundary  0.854694  0.863095\n",
       "58213                       St. Mary River near Babb, MT  0.752084  0.799242\n",
       "58223          Swiftcurrent Creek at Sherburne Reservoir  0.660619  0.715382\n",
       "58290          Frenchman River at International Boundary  0.332411  0.183949\n",
       "58292                                Rock Creek at Mouth -0.051166 -0.999370\n",
       "58308                     Milk River at Eastern Crossing  0.374327  0.641805\n",
       "58328                               Beaver Creek Bowdoin  0.682549  0.494172\n",
       "58346                           Big Sandy Creek at Mouth  0.813249  0.431143\n",
       "58356              Lodge Creek at International Boundary  0.436502 -0.380760\n",
       "58363             Battle Creek at International Boundary  0.507260 -0.119981\n",
       "58408  Milk River at Western Crossing of Internationa...  0.544777  0.492841\n",
       "58418                             Peoples Creek at Mouth  0.426048  0.509721\n",
       "58425                               Clear Creek at Mouth  0.808600  0.545935\n",
       "58643  North Fork Milk River above St Mary Canal near...  0.365203  0.323074"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the 'Cal KGE' column with calibrate_kge array\n",
    "results['Cal KGE'] = calibration_kge\n",
    "\n",
    "# Populate the 'Val KGE' column with validate_kge array\n",
    "results['Val KGE'] = validation_kge\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c05cb4-7223-4172-93ad-bd26bcbb2b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
