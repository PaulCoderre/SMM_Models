{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c218d504-4824-45fe-8978-137ebc5a303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b81162e-656e-48d5-8f52-1f13b1d75ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_zero_files(wb_dir, max_lines=200, subbasin_id=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks all HYPE water balance files for non-zero and non-NaN values. Returns a list of files with values. \n",
    "    Max_lines can be used to reduce computational demand. Can check the full file or just for a given subbasin (useful to\n",
    "    confirm regionalization)\n",
    "\n",
    "    Parameters:\n",
    "    wb_dir (str): The directory path where the files are stored.\n",
    "    max_lines (int, optional): The maximum number of lines to read from each file for performance optimization. Default is 200.\n",
    "    subbasin_id (int or str, optional): A specific subbasin ID to check for non-zero values in the file. \n",
    "                                        If provided, the function will only check the column corresponding to this subbasin ID.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of filenames that contain non-zero, non-NaN values in the specified subbasin column or the entire file.\n",
    "    \"\"\"\n",
    "        \n",
    "    non_zero_files = []\n",
    "    \n",
    "    \n",
    "    # Iterate through each file in the directory\n",
    "    for filename in os.listdir(wb_dir):\n",
    "        if filename.startswith('WB') and filename.endswith('.txt'):\n",
    "            file_path = os.path.join(wb_dir, filename)\n",
    "            \n",
    "            # Load only the first 'max_lines' lines into a DataFrame\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, index_col=0, sep='\\t', nrows=max_lines)\n",
    "                \n",
    "                # Convert only numeric headers to integers, ignore non-numeric ones\n",
    "                try:\n",
    "                    df.columns = pd.to_numeric(df.columns, errors='coerce').astype('Int64')  # 'Int64' to allow NaN for non-convertible columns\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting headers to integers in {filename}: {e}\")\n",
    "                \n",
    "                # If subbasin_id is provided, convert it to an integer\n",
    "                if subbasin_id is not None:\n",
    "                    try:\n",
    "                        subbasin_id = int(subbasin_id)\n",
    "                    except ValueError:\n",
    "                        print(f\"Subbasin ID {subbasin_id} is not a valid integer.\")\n",
    "                        continue\n",
    "                \n",
    "                # If subbasin_id is provided and found in columns, filter the DataFrame\n",
    "                if subbasin_id in df.columns:\n",
    "                    df = df[[subbasin_id]]\n",
    "                \n",
    "                # Check if there are any non-zero and non-NaN values in the DataFrame\n",
    "                if ((df != 0) & df.notna()).any().any():\n",
    "                    non_zero_files.append(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    return non_zero_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78210b2-bfcb-49fd-bbb7-c68a132d221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_matching_strings(list1, list2):\n",
    "    \"\"\"\n",
    "    Finds and returns a list of strings that do not match between two lists.\n",
    "\n",
    "    Parameters:\n",
    "    list1 (list): The first list of strings to compare.\n",
    "    list2 (list): The second list of strings to compare.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of strings that are present in either list1 or list2, but not in both.\n",
    "    \"\"\"\n",
    "    # Convert lists to sets for efficient comparison\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    \n",
    "    # Find strings that are in list1 but not in list2, and vice versa\n",
    "    non_matching_from_list1 = set1 - set2\n",
    "    non_matching_from_list2 = set2 - set1\n",
    "    \n",
    "    # Combine the non-matching strings from both lists\n",
    "    non_matching = list(non_matching_from_list1.union(non_matching_from_list2))\n",
    "    \n",
    "    return non_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76f6b89-5421-4bf0-ad94-f6aa58739fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_non_zero_files(file_list):\n",
    "    \"\"\"\n",
    "    Reads multiple files into an xarray DataArray from a provided list of filenames.\n",
    "\n",
    "    Parameters:\n",
    "    file_list (list): A list of file paths to read.\n",
    "\n",
    "    Returns:\n",
    "    xarray.DataArray: An xarray DataArray containing the data from all specified files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read all files into a single DataArray\n",
    "        data_array = xr.open_mfdataset(file_list, combine='by_coords')\n",
    "        return data_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading files: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457aad60-c19d-400b-b23f-6b8a28493e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wb_files(file_list, wb_dir, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Reads multiple text files into a single xarray DataArray with an additional dimension for filenames. Filter to only include specified date range and return a WBs DataArray\n",
    "    with the full range to include initial conditions as well as a WBf DataArray containing the range except for the first date.\n",
    "\n",
    "    Parameters:\n",
    "    file_list (list): A list of filenames to append to the directory path.\n",
    "    wb_dir (str): The base directory path.\n",
    "    start_date (str): The start date for filtering the data.\n",
    "    end_date (str): The end date for filtering the data.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two xarray DataArrays:\n",
    "        - filtered_wbs_components: DataArray containing data within the date range.\n",
    "        - filtered_wbf_components: DataArray containing data without the first date.\n",
    "    \"\"\"\n",
    "    # Create an empty list to store DataArrays and filenames\n",
    "    ensemble_member_list = []\n",
    "    filenames = []\n",
    "\n",
    "    # Create full file paths\n",
    "    full_file_paths = [os.path.join(wb_dir, filename) for filename in file_list]\n",
    "    \n",
    "    # Read each file and store in the ensemble_member_list\n",
    "    for path in full_file_paths:\n",
    "        try:\n",
    "            # Determine if the filename starts with 'WBs' to skip the first line\n",
    "            skip_first_line = os.path.basename(path).startswith('WBs')\n",
    "            # Read the file into a pandas DataFrame normally\n",
    "            df = pd.read_csv(path, sep='\\t', index_col=0)  # Adjust the separator and index column as needed\n",
    "            \n",
    "            # Drop the first row if the filename starts with 'WBs'\n",
    "            if os.path.basename(path).startswith('WBs'):\n",
    "                df = df.drop(df.index[0])  # Drop the first row\n",
    "            \n",
    "            # Convert the index to datetime and ensure subbasin columns are integers\n",
    "            df.index = pd.to_datetime(df.index)  # Convert DATE index to datetime\n",
    "            df.columns = df.columns.astype(int)  # Convert subbasin columns to integers\n",
    "            \n",
    "            # Ensure all values are numeric (this may convert non-numeric entries to NaN)\n",
    "            df = df.apply(pd.to_numeric, errors='coerce')\n",
    "            \n",
    "            # Create an xarray DataArray for the current file\n",
    "            data_array = xr.DataArray(\n",
    "                df.values,\n",
    "                dims=('DATE', 'subbasin'),\n",
    "                coords={'DATE': df.index,\n",
    "                        'subbasin': df.columns}\n",
    "            )\n",
    "            \n",
    "            # Assign the filename as an additional dimension\n",
    "            data_array = data_array.expand_dims(wb=1)  # Create a new dimension for the filename\n",
    "            data_array.attrs['filename'] = os.path.basename(path)  # Optionally store the filename in the attributes\n",
    "\n",
    "            # Add the DataArray to the ensemble member list\n",
    "            ensemble_member_list.append(data_array)\n",
    "            filenames.append(os.path.basename(path).split('.')[0])  # Store the filename without extension\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {path}: {e}\")\n",
    "\n",
    "    # Concatenate all DataArrays along the new 'wb' dimension\n",
    "    if ensemble_member_list:\n",
    "        combined_data_array = xr.concat(ensemble_member_list, dim='wb')  # Concatenate along the wb dimension\n",
    "        combined_data_array.coords['wb'] = filenames  # Assign the filenames to the new dimension\n",
    "        \n",
    "        # Filter the DataArray to include only the specified date range\n",
    "        filtered_wbs_components = combined_data_array.sel(DATE=slice(start_date, end_date))\n",
    "        \n",
    "        # Exclude the first date from the filtered_wbs_components\n",
    "        first_date = pd.to_datetime(start_date)\n",
    "        filtered_wbf_components = combined_data_array.sel(DATE=slice(first_date + pd.Timedelta(days=1), end_date))\n",
    "\n",
    "        return filtered_wbs_components, filtered_wbf_components\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39b1874-cf52-45dc-bd1c-a443534d4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precipitation(filtered_wbf_components):\n",
    "    \"\"\"\n",
    "    Filters the DataArray for wb entries that start with 'WBf_rain' and 'WBf_snowfall',\n",
    "    sums the rainfall and snowfall components, and returns the total precipitation.\n",
    "\n",
    "    Parameters:\n",
    "    filtered_wbf_components (xarray.DataArray): The DataArray filtered by date.\n",
    "\n",
    "    Returns:\n",
    "    xarray.DataArray: Total precipitation (rainfall + snowfall) summed over all 'wb' entries.\n",
    "    \"\"\"\n",
    "    # Filter for wb entries that start with 'WBf_rain'\n",
    "    rainfall = filtered_wbf_components.sel(wb=filtered_wbf_components.wb.str.startswith('WBf_rain'))\n",
    "    rainfall_sum = rainfall.sum(dim='wb')\n",
    "    \n",
    "    # Filter for wb entries that start with 'WBf_snowfall'\n",
    "    snowfall = filtered_wbf_components.sel(wb=filtered_wbf_components.wb.str.startswith('WBf_snowfall'))\n",
    "    snowfall_sum = snowfall.sum(dim='wb')\n",
    "    \n",
    "    # Calculate the total precipitation (rainfall + snowfall)\n",
    "    total_precip = rainfall_sum + snowfall_sum\n",
    "    \n",
    "    rainfall_frac= rainfall_sum/total_precip\n",
    "    snowfall_frac= snowfall_sum/total_precip\n",
    "    \n",
    "    print(f'Full Domain Rainfall Fraction: {rainfall_frac.mean()} \\n'\n",
    "    f'Full Domain Rainfall Fraction {snowfall_frac.mean()}')\n",
    "    \n",
    "    return total_precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c9646e-de9e-449c-9a71-5612baf4a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wbf(filtered_wbf_components, subbasin, file_name):\n",
    "    \"\"\"\n",
    "    Filters the DataArray for wb entries that start with 'WBf_satsurfaceflow_soillayer1_lstream',\n",
    "    selects the specified subbasin, and returns the summed saturated surface runoff for that subbasin.\n",
    "\n",
    "    Parameters:\n",
    "    filtered_wbf_components (xarray.DataArray): The DataArray filtered by date.\n",
    "    subbasin (int): The specific subbasin to select.\n",
    "\n",
    "    Returns:\n",
    "    xarray.DataArray: Summed saturated surface runoff for the specified subbasin.\n",
    "    \"\"\"\n",
    "    # Filter for wb entries that start with requited name\n",
    "    wbf = filtered_wbf_components.sel(wb=filtered_wbf_components.wb.str.startswith(file_name))\n",
    "    \n",
    "    # Select the specified subbasin and sum the values\n",
    "    wbf = wbf.sel(subbasin=subbasin).sum()\n",
    "    \n",
    "    return wbf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247cb0b8-3d84-4e92-a758-5a6233bd4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wbs(filtered_wbs_components, subbasin, file_name, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Filters the DataArray for wbs entries,\n",
    "    selects the specified subbasin, and returns the change in storage for that subbasin.\n",
    "\n",
    "    Parameters:\n",
    "    filtered_wbs_components (xarray.DataArray): The DataArray filtered by date.\n",
    "    subbasin (int): The specific subbasin to select.\n",
    "\n",
    "    Returns:\n",
    "    xarray.DataArray: Summed saturated surface runoff for the specified subbasin.\n",
    "    \"\"\"\n",
    "    # Filter for wb entries that start with requited name\n",
    "    wbs = filtered_wbs_components.sel(wb=filtered_wbf_components.wb.str.startswith(file_name))\n",
    "\n",
    "    # extract changes in storage\n",
    "    wbs= wbs.sel(subbasin=subbasin)\n",
    "    wbs= wbs.sel(DATE= end_date).values - wbs.sel(DATE= start_date).values\n",
    "    \n",
    "    return wbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00608e-d531-472b-9ce7-7452f0b351b3",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0eebb4-0217-4c05-a93f-7d92d4b9cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory containing wb outputs\n",
    "wb_dir= '../../model/model_versions/v_6/v_6_2/v6_2_waterbal/'\n",
    "\n",
    "# date range for wb calculations, set to sometime after the first year in the model run to reduce effects of initial conditions\n",
    "start_date = '1997-04-01'\n",
    "end_date = '2005-09-30'\n",
    "\n",
    "subbasin= 58363"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5ab2d-8406-4e78-8cf8-06ffc810e236",
   "metadata": {},
   "source": [
    "### Find Non-Zero WB Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f97728b-cc67-4b52-a6a9-8ecf654715ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk_non_zero_files = find_non_zero_files(wb_dir, subbasin_id=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09257bc0-4469-4315-99d6-eedec8b3d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm_non_zero_files= find_non_zero_files(wb_dir, subbasin_id=58208)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57c6063f-77a3-4bd6-badc-51f2fcc5ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WBf_precipitation__iwet.txt', 'WBf_evaporation_ilake_.txt', 'WBs_iwet.txt', 'WBf_flow_ilake_mriver.txt', 'WBf_snowmelt_via_macropore_snow_soillayer1.txt', 'WBf_precipitation__ilake.txt', 'WBf_flow_lstream_ilake.txt', 'WBs_ilake.txt', 'WBf_evaporation_iwet_.txt']\n"
     ]
    }
   ],
   "source": [
    "# find WB components that are present in the milk but not the St Mary\n",
    "non_matching_strings = find_non_matching_strings(stm_non_zero_files, milk_non_zero_files)\n",
    "print(non_matching_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb335d95-6d12-48b0-960f-df7309acd9e3",
   "metadata": {},
   "source": [
    "# Land Class Water Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f580e67b-d5d1-40d3-a4a8-80a1d3a1c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read WB files into DataArray\n",
    "filtered_wbs_components, filtered_wbf_components = read_wb_files(milk_non_zero_files, wb_dir, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b79caaf4-94c5-4c33-9318-41e2fe9b2dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WBf_evaporation_ilake_' 'WBf_evaporation_iwet_' 'WBf_evaporation_snow_'\n",
      " 'WBf_evaporation_soillayer1_' 'WBf_evaporation_soillayer2_'\n",
      " 'WBf_flow_ilake_mriver' 'WBf_flow_lstream_ilake'\n",
      " 'WBf_flow_lstream_mriver' 'WBf_flow_mriver_olake'\n",
      " 'WBf_flow_olake_mriver_maindownstream'\n",
      " 'WBf_percolation_soillayer1_soillayer2'\n",
      " 'WBf_percolation_soillayer2_soillayer3' 'WBf_precipitation__ilake'\n",
      " 'WBf_precipitation__iwet' 'WBf_rain_surfacerunoff__lstream'\n",
      " 'WBf_rain_via_macropore__soillayer1' 'WBf_rain_via_macropore__soillayer3'\n",
      " 'WBf_rain__soillayer1' 'WBf_satsurfaceflow_soillayer1_lstream'\n",
      " 'WBf_snowfall__snow' 'WBf_snowmelt_snow_soillayer1'\n",
      " 'WBf_snowmelt_surfacerunoff_snow_lstream'\n",
      " 'WBf_snowmelt_via_macropore_snow_soillayer1'\n",
      " 'WBf_snowmelt_via_macropore_snow_soillayer3'\n",
      " 'WBf_soilrunoff_soillayer1_lstream' 'WBf_soilrunoff_soillayer2_lstream'\n",
      " 'WBf_soilrunoff_soillayer3_lstream' 'WBs_ilake' 'WBs_iwet' 'WBs_lstream'\n",
      " 'WBs_mriver' 'WBs_snow' 'WBs_soillayer1' 'WBs_soillayer2'\n",
      " 'WBs_soillayer3']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_wbf_components.wb.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fbedb-7d66-45fb-84cb-b6b9d5106f8f",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e6200-6fa7-4fdc-954a-a8a407f1302d",
   "metadata": {},
   "source": [
    "### Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d5006e5-04bc-49d8-9a8f-144ffa1e9171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Domain Rainfall Fraction: <xarray.DataArray ()>\n",
      "array(0.6644147) \n",
      "Full Domain Rainfall Fraction <xarray.DataArray ()>\n",
      "array(0.3355853)\n"
     ]
    }
   ],
   "source": [
    "total_precip = precipitation(filtered_wbf_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d8501-a41e-4b35-bc86-9708fd20a5f0",
   "metadata": {},
   "source": [
    "### Land Class Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b96fe20-2f5a-42b4-ba31-67aa499b23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find precipitation flux\n",
    "precip_landclass= total_precip.sel(subbasin=subbasin).sum().values\n",
    "\n",
    "# find runoff fluxes\n",
    "sat_surface_runoff= calculate_wbf(filtered_wbf_components, subbasin, 'WBf_satsurfaceflow_soillayer1_lstream')\n",
    "\n",
    "# note this is considerered as part of the rain input so it will be subtracted twice to consider it as an output\n",
    "rain_runoff= calculate_wbf(filtered_wbf_components, subbasin, 'WBf_rain_surfacerunoff__lstream')\n",
    "\n",
    "snowmelt_runoff = calculate_wbf(filtered_wbf_components, subbasin, 'WBf_snowmelt_surfacerunoff_snow_lstream')\n",
    "\n",
    "soil_layer1_runoff = calculate_wbf(filtered_wbf_components, subbasin, 'WBf_soilrunoff_soillayer1_lstream')\n",
    "\n",
    "soil_layer2_runoff = calculate_wbf(filtered_wbf_components, subbasin, 'WBf_soilrunoff_soillayer2_lstream')\n",
    "\n",
    "soil_layer3_runoff = calculate_wbf(filtered_wbf_components, subbasin, 'WBf_soilrunoff_soillayer3_lstream')\n",
    "\n",
    "# find et fluxes\n",
    "et_sl1 = calculate_wbf(filtered_wbf_components, subbasin, 'WBf_evaporation_soillayer1')\n",
    "\n",
    "et_sl2 = calculate_wbf(filtered_wbf_components, subbasin, 'WBf_evaporation_soillayer2')\n",
    "\n",
    "sublimation = calculate_wbf(filtered_wbf_components, subbasin, 'WBf_evaporation_snow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd3f98-1bd6-4fe4-b6d0-a7485806e8ff",
   "metadata": {},
   "source": [
    "### Land Class Storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af2d9650-587d-4f8b-a0a6-b97aab7be694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate changes in storage\n",
    "delta_stor_sl1= calculate_wbs(filtered_wbs_components, subbasin, 'WBs_soillayer1', start_date, end_date)\n",
    "\n",
    "delta_stor_sl2= calculate_wbs(filtered_wbs_components, subbasin, 'WBs_soillayer2', start_date, end_date)\n",
    "\n",
    "delta_stor_sl3= calculate_wbs(filtered_wbs_components, subbasin, 'WBs_soillayer3', start_date, end_date)\n",
    "\n",
    "delta_stor_snow= calculate_wbs(filtered_wbs_components, subbasin, 'WBs_snow', start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd89dc-01f1-4b1c-862a-797e8305408c",
   "metadata": {},
   "source": [
    "#### Adjust Snow Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72f1dd4f-f1db-437e-af5b-3722c5766468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find vertical snow fluxes within each land class \n",
    "snowmelt_macro_sl1=  calculate_wbf(filtered_wbf_components, subbasin,'WBf_snowmelt_via_macropore_snow_soillayer1')\n",
    "\n",
    "snowmelt_macro_sl2=  calculate_wbf(filtered_wbf_components, subbasin,'WBf_snowmelt_via_macropore_snow_soillayer2')\n",
    "\n",
    "snowmelt_macro_sl3=  calculate_wbf(filtered_wbf_components, subbasin,'WBf_snowmelt_via_macropore_snow_soillayer3')\n",
    "\n",
    "snowmelt_infiltration_sl1=  calculate_wbf(filtered_wbf_components, subbasin,'WBf_WBf_snowmelt_snow_soillayer1.txt')\n",
    "\n",
    "# add back vertical snow changes to only consider horizontal fluxes\n",
    "delta_stor_snow_subbasin= delta_stor_snow + snowmelt_runoff + snowmelt_macro_sl1 + snowmelt_macro_sl2 + snowmelt_macro_sl3 + snowmelt_infiltration_sl1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52771433-8e25-4582-9747-8f46ee6ec3ab",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6888137f-51b1-47b2-b18f-61f99a390c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precipitation Flux= 1029198457.1181327\n",
      "Evapotranspiration Flux= 1019353482.5522885\n",
      "Runoff to Local Stream= 34991466.838923424\n",
      "Change in Storage= [-21975882.639648]\n"
     ]
    }
   ],
   "source": [
    "# precipitation\n",
    "p= precip_landclass\n",
    "\n",
    "# evapotranspiration\n",
    "e= et_sl1 + et_sl2 + sublimation\n",
    "\n",
    "# runoff from land class \n",
    "r=  sat_surface_runoff + 2 * rain_runoff + snowmelt_runoff + soil_layer1_runoff + soil_layer2_runoff + soil_layer3_runoff\n",
    "\n",
    "# change in storage\n",
    "delta_s= delta_stor_sl1 + delta_stor_sl2 + delta_stor_sl3 + delta_stor_snow\n",
    "\n",
    "print(f'Precipitation Flux= {p}\\n'\n",
    "f'Evapotranspiration Flux= {e}\\n'\n",
    "f'Runoff to Local Stream= {r}\\n'\n",
    "f'Change in Storage= {delta_s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd4c7632-520d-4492-91b1-f01ab3f2104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the water balance\n",
    "balance= p -e - r - delta_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6379c3-0fea-43de-b9ee-c5d3e210d794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land Class WB Error= [-3170609.63343124]\n",
      "Land Class % Error= [0.14427678]\n"
     ]
    }
   ],
   "source": [
    "print(f'Land Class WB Error= {balance}\\n'\n",
    "     f'Land Class % Error= {np.abs(balance/delta_s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459150c-cded-40e4-af38-baf2faf525fe",
   "metadata": {},
   "source": [
    "# Subbasin Water Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6ab38-23a7-408f-a11c-51dc80a95354",
   "metadata": {},
   "source": [
    "### Internal Wetland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56a541f8-2f10-463a-b1d5-59dc04b177af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find precipitation into iwet\n",
    "precip_iwet= calculate_wbf(filtered_wbf_components, subbasin, 'WBf_precipitation__iwet')\n",
    "\n",
    "# find et from iwet\n",
    "evap_iwet= calculate_wbf(filtered_wbf_components, subbasin, 'WBf_evaporation_iwet')\n",
    "\n",
    "# find change in storage from iwet\n",
    "delta_stor_iwet= calculate_wbs(filtered_wbs_components, subbasin, 'WBs_iwet', start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7de7b-baba-431b-8e35-07d2764d126e",
   "metadata": {},
   "source": [
    "### Internal Lakes (Potholes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebf75760-7f89-401f-a5c8-6d792011d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find precipitation into ilake\n",
    "precip_ilake= calculate_wbf(filtered_wbf_components, subbasin, 'WBf_precipitation__ilake')\n",
    "\n",
    "# find inflow to ilake\n",
    "inflow_ilake= calculate_wbf(filtered_wbf_components, subbasin, 'WBf_flow_lstream_ilake')\n",
    "\n",
    "# find evap ilake\n",
    "evap_ilake= calculate_wbf(filtered_wbf_components, subbasin, 'WBf_evaporation_ilake')\n",
    "\n",
    "# find outflow ilake\n",
    "outflow_ilake= calculate_wbf(filtered_wbf_components, subbasin, 'WBf_flow_ilake_mriver')\n",
    "\n",
    "# find change in storage ilake\n",
    "delta_stor_ilake= calculate_wbs(filtered_wbs_components, subbasin, 'WBs_ilake', start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d0e5f55-4b63-4dcd-9787-afe22e1071fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilake_wb= precip_ilake + inflow_ilake - evap_ilake - outflow_ilake - delta_stor_ilake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76c12593-338a-4ece-af5c-7599d812228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilake WB Error= [5.80976879]\n"
     ]
    }
   ],
   "source": [
    "print(f'ilake WB Error= {ilake_wb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a49582-49a4-40ce-b722-45a787d28a13",
   "metadata": {},
   "source": [
    "# Runoff Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ba277d6-9e83-4b0b-81b9-e7b976292449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find outlflow from subbasin to main river\n",
    "lstream_mriver= calculate_wbf(filtered_wbf_components, subbasin, 'WBf_flow_lstream_mriver')\n",
    "\n",
    "# total subbasin runoff is sum of ilake outflow and lstream straight to mriver\n",
    "subbasin_runoff= lstream_mriver + outflow_ilake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "395f1d59-fc21-4de1-8581-bf1524331262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the runoff ratio\n",
    "total_subbasin_precip= precip_landclass + precip_ilake + precip_iwet\n",
    "\n",
    "runoff_ratio= subbasin_runoff/total_subbasin_precip * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52e30e0b-6227-47e5-84b0-ff033495fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Precipitation= 1148637649.7482162\n",
      "Total Runoff= 14131369.238403074\n",
      "Runoff Ratio (%) for Subbasin: 58363 = 1.2302721612425556\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Precipitation= {total_subbasin_precip}\\n'\n",
    "f'Total Runoff= {subbasin_runoff}\\n'\n",
    "f'Runoff Ratio (%) for Subbasin: {subbasin} = {runoff_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf7a5f-8e84-4167-9343-f9331247cbf7",
   "metadata": {},
   "source": [
    "# Results Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7cb91243-5e9e-4a60-aa93-e3b03815ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data for the DataFrame\n",
    "data = {\n",
    "    'Precipitation': {\n",
    "        'Landclass Precipitation (%)': precip_landclass/total_subbasin_precip,\n",
    "        'Pothole Precipitation (%)': precip_ilake/total_subbasin_precip,\n",
    "        'Total Precipitation (m3)': total_subbasin_precip,\n",
    "    },\n",
    "    'Evapotranspiration (fraction of landclass precip)': {\n",
    "        'ET SL 1': et_sl1 / precip_landclass,\n",
    "        'ET SL 2': et_sl2 / precip_landclass,\n",
    "        'Sublimation': sublimation / precip_landclass,\n",
    "        'Total ET Flux': (et_sl1 + et_sl2 + sublimation) / precip_landclass\n",
    "    },\n",
    "    'Runoff (fraction of landclass precip)': {\n",
    "        'Surface Runoff': (sat_surface_runoff + rain_runoff + snowmelt_runoff) / precip_landclass,\n",
    "        'SL 1 Flow': soil_layer1_runoff / precip_landclass,\n",
    "        'SL 2 Flow': soil_layer2_runoff / precip_landclass,\n",
    "        'SL 3 Flow': soil_layer3_runoff / precip_landclass,\n",
    "        'Total Runoff Flux': (sat_surface_runoff + 2 * rain_runoff + snowmelt_runoff + soil_layer1_runoff + soil_layer2_runoff + soil_layer3_runoff) / precip_landclass\n",
    "    },\n",
    "    'Change in Storage (fraction of landclass precip)': {\n",
    "        'Change in Storage SL1': delta_stor_sl1 / precip_landclass,\n",
    "        'Change in Storage SL2': delta_stor_sl2 / precip_landclass,\n",
    "        'Change in Storage SL3': delta_stor_sl3 / precip_landclass,\n",
    "        'Storage Change': (delta_stor_sl1 + delta_stor_sl2 + delta_stor_sl3) / precip_landclass\n",
    "    },\n",
    "    'Wetlands': {\n",
    "        'Inflow (fraction of landclass precip)': inflow_ilake/precip_landclass,\n",
    "        'Evaporation (fraction of inputs)': evap_ilake/(inflow_ilake + precip_ilake),\n",
    "        'Outflow (fraction of inputs)': outflow_ilake/(inflow_ilake + precip_ilake),\n",
    "        'Change in Storage (fraction of inputs)': delta_stor_ilake/(inflow_ilake + precip_ilake)\n",
    "    },\n",
    "    'Prairie Potholes': {\n",
    "        'Inflow (fraction of landclass precip)': inflow_ilake/precip_landclass,\n",
    "        'Evaporation (fraction of inputs)': evap_ilake/(inflow_ilake + precip_ilake),\n",
    "        'Outflow (fraction of inputs)': outflow_ilake/(inflow_ilake + precip_ilake),\n",
    "        'Change in Storage (fraction of inputs)': delta_stor_ilake/(inflow_ilake + precip_ilake)\n",
    "    },\n",
    "        'Main River (fraction of total precip)': { \n",
    "        'Flow from Local Stream (fraction of total runoff)': lstream_mriver/ (lstream_mriver + outflow_ilake),\n",
    "        'Flow from Prairie Potholes (fraction of total runoff)': outflow_ilake/ (lstream_mriver + outflow_ilake),  \n",
    "        'Runoff Ratio': runoff_ratio,\n",
    "        'Total ET': et_sl1 + et_sl2 + sublimation + evap_ilake + evap_iwet,\n",
    "        'Total Change in Storage': delta_stor_sl1 + delta_stor_sl2 + delta_stor_sl3 + delta_stor_ilake + delta_stor_iwet,\n",
    "        'Total Runoff (m3)': (sat_surface_runoff + rain_runoff + snowmelt_runoff)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert dictionary to multi-index DataFrame\n",
    "df = pd.concat({k: pd.DataFrame(v, index=[0]) for k, v in data.items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19410a90-eecf-4fee-ba2a-c59a161520f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MultiIndex for clearer separation\n",
    "df.columns = pd.MultiIndex.from_tuples(\n",
    "    [(category, var) for category, variables in data.items() for var in variables.keys()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cdf4654c-d068-4768-adf9-823e39136a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Precipitation</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Evapotranspiration (fraction of landclass precip)</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Runoff (fraction of landclass precip)</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Prairie Potholes</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Main River (fraction of total precip)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Landclass Precipitation (%)</th>\n",
       "      <th>Pothole Precipitation (%)</th>\n",
       "      <th>Total Precipitation (m3)</th>\n",
       "      <th>ET SL 1</th>\n",
       "      <th>ET SL 2</th>\n",
       "      <th>Sublimation</th>\n",
       "      <th>Total ET Flux</th>\n",
       "      <th>Surface Runoff</th>\n",
       "      <th>SL 1 Flow</th>\n",
       "      <th>SL 2 Flow</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflow (fraction of landclass precip)</th>\n",
       "      <th>Evaporation (fraction of inputs)</th>\n",
       "      <th>Outflow (fraction of inputs)</th>\n",
       "      <th>Change in Storage (fraction of inputs)</th>\n",
       "      <th>Flow from Local Stream (fraction of total runoff)</th>\n",
       "      <th>Flow from Prairie Potholes (fraction of total runoff)</th>\n",
       "      <th>Runoff Ratio</th>\n",
       "      <th>Total ET</th>\n",
       "      <th>Total Change in Storage</th>\n",
       "      <th>Total Runoff (m3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896017</td>\n",
       "      <td>0.103983</td>\n",
       "      <td>1.148638e+09</td>\n",
       "      <td>0.632836</td>\n",
       "      <td>0.261003</td>\n",
       "      <td>0.096595</td>\n",
       "      <td>0.990434</td>\n",
       "      <td>0.009746</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032045</td>\n",
       "      <td>0.948834</td>\n",
       "      <td>0.092713</td>\n",
       "      <td>-0.041547</td>\n",
       "      <td>5.799506e-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.230272</td>\n",
       "      <td>1.163975e+09</td>\n",
       "      <td>-2.830650e+07</td>\n",
       "      <td>1.003108e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Precipitation                            \\\n",
       "  Landclass Precipitation (%) Pothole Precipitation (%)   \n",
       "0                    0.896017                  0.103983   \n",
       "\n",
       "                           Evapotranspiration (fraction of landclass precip)  \\\n",
       "  Total Precipitation (m3)                                           ET SL 1   \n",
       "0             1.148638e+09                                          0.632836   \n",
       "\n",
       "                                      Runoff (fraction of landclass precip)  \\\n",
       "    ET SL 2 Sublimation Total ET Flux                        Surface Runoff   \n",
       "0  0.261003    0.096595      0.990434                              0.009746   \n",
       "\n",
       "                       ...                      Prairie Potholes  \\\n",
       "  SL 1 Flow SL 2 Flow  ... Inflow (fraction of landclass precip)   \n",
       "0  0.001759  0.000086  ...                              0.032045   \n",
       "\n",
       "                                                                 \\\n",
       "  Evaporation (fraction of inputs) Outflow (fraction of inputs)   \n",
       "0                         0.948834                     0.092713   \n",
       "\n",
       "                                          \\\n",
       "  Change in Storage (fraction of inputs)   \n",
       "0                              -0.041547   \n",
       "\n",
       "              Main River (fraction of total precip)  \\\n",
       "  Flow from Local Stream (fraction of total runoff)   \n",
       "0                                      5.799506e-09   \n",
       "\n",
       "                                                                      \\\n",
       "  Flow from Prairie Potholes (fraction of total runoff) Runoff Ratio   \n",
       "0                                                1.0        1.230272   \n",
       "\n",
       "                                                           \n",
       "       Total ET Total Change in Storage Total Runoff (m3)  \n",
       "0  1.163975e+09           -2.830650e+07      1.003108e+07  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51853fc7-0eb5-4d41-876f-b6aba15b365b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
