{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1765ab45-fa96-42b3-a523-696b2f5da8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bbe2c19-abb1-4fa9-a0a8-303b5fa5ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where Hype outputs are saved\n",
    "hype_directory= \"../../SMM_Models/hype/model/model_versions/v_6/v_6_2/results/\"\n",
    "results_dir= './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f8a7e7-224c-4ba0-9095-79b5c0ead694",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_ranges = [('1980-10-01', '1984-09-30'),\n",
    "               ('1989-10-01', '1998-09-30'),\n",
    "               ('2003-10-01', '2007-09-30'),\n",
    "               ('2012-10-01', '2015-09-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f325d4-8887-402c-ae50-6c684f41e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ranges = [('1984-10-01', '1989-09-30'),\n",
    "               ('1998-10-01', '2003-09-30'),\n",
    "               ('2007-10-01', '2012-09-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "269a5285-4d5d-42bb-9e8d-584dd4886cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the directory\n",
    "files = os.listdir(hype_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1b9b2a-1d6a-4dc6-b911-37ae76548c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ./0058208.csv\n",
      "Processed and saved: ./0058213.csv\n",
      "Processed and saved: ./0058223.csv\n",
      "Processed and saved: ./0058290.csv\n",
      "Processed and saved: ./0058308.csv\n",
      "Processed and saved: ./0058328.csv\n",
      "Processed and saved: ./0058346.csv\n",
      "Processed and saved: ./0058356.csv\n",
      "Processed and saved: ./0058363.csv\n",
      "Processed and saved: ./0058398.csv\n",
      "Processed and saved: ./0058408.csv\n",
      "Processed and saved: ./0058418.csv\n",
      "Processed and saved: ./0058425.csv\n",
      "Processed and saved: ./0058643.csv\n"
     ]
    }
   ],
   "source": [
    "# Process each file starting with '00' and ending with '.txt'\n",
    "for file in files:\n",
    "    if file.startswith('00') and file.endswith('.txt'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(hype_directory, file)\n",
    "\n",
    "        # Read the file into a DataFrame\n",
    "        try:\n",
    "            flow = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Drop the first row (assumed header or invalid row)\n",
    "            flow = flow.drop(flow.index[0])\n",
    "\n",
    "            # Ensure the index is datetime\n",
    "            flow.index = pd.to_datetime(flow.index)\n",
    "\n",
    "            # Convert all columns to float\n",
    "            flow = flow.astype(float)\n",
    "\n",
    "            # Replace -9999 with NaN\n",
    "            flow.replace(-9999, np.nan, inplace=True)\n",
    "\n",
    "            # Remove rows with NaN values in 'cout' or 'rout'\n",
    "            flow_clean = flow.dropna(subset=['cout', 'rout'])\n",
    "\n",
    "            # Move the index to a column first\n",
    "            flow_clean = flow_clean.reset_index()\n",
    "\n",
    "            # Rename columns\n",
    "            flow_clean = flow_clean.rename(columns={'DATE': 'date', 'cout': 'sim', 'rout': 'obs'})\n",
    "\n",
    "            # Reorder columns\n",
    "            flow_clean = flow_clean[['date', 'obs', 'sim']]\n",
    "\n",
    "            # Save the processed DataFrame to a CSV file\n",
    "            csv_file_name = os.path.splitext(file)[0] + '.csv'  # Replace .txt with .csv\n",
    "            csv_file_path = os.path.join(results_dir, csv_file_name)\n",
    "            flow_clean.to_csv(csv_file_path, index=False)  # Save the cleaned DataFrame to CSV\n",
    "\n",
    "            print(f\"Processed and saved: {csv_file_path}\")  # Print success message\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")  # Handle any errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be4548-7f18-4f42-9881-838f33fcbf42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
